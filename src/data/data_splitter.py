"""
ğŸ‰ ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ML í”„ë¡œì íŠ¸ - ë°ì´í„° ë¶„í•  ëª¨ë“ˆ
DataSplitter í´ë˜ìŠ¤: Train/Validation/Test ì„¸íŠ¸ ë¶„í•  ë° ê· í˜• í™•ì¸
"""

import logging
from typing import Dict, List, Optional, Union, Tuple
import numpy as np
import pandas as pd
from pathlib import Path
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class DataSplitter:
    """
    ë°ì´í„°ì…‹ì„ Train/Validation/Test ì„¸íŠ¸ë¡œ ë¶„í• í•˜ëŠ” í´ë˜ìŠ¤
    
    ê¸°ëŠ¥:
    - ì¸µí™” ìƒ˜í”Œë§ (ë‹¹ë„ êµ¬ê°„ë³„ ê· ë“± ë¶„í• )
    - ë¶„í•  ë¹„ìœ¨ ì„¤ì • ê°€ëŠ¥
    - ë¶„í•  ê²°ê³¼ ê²€ì¦ ë° ì‹œê°í™”
    - ì¬í˜„ ê°€ëŠ¥í•œ ë¶„í•  (random seed)
    """
    
    def __init__(self, train_ratio: float = 0.7, 
                 val_ratio: float = 0.15, 
                 test_ratio: float = 0.15,
                 random_state: int = 42):
        """
        DataSplitter ì´ˆê¸°í™”
        
        Args:
            train_ratio (float): í›ˆë ¨ ì„¸íŠ¸ ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.7)
            val_ratio (float): ê²€ì¦ ì„¸íŠ¸ ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.15)
            test_ratio (float): í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.15)
            random_state (int): ì¬í˜„ì„±ì„ ìœ„í•œ ëœë¤ ì‹œë“œ (ê¸°ë³¸ê°’: 42)
        """
        # ë¹„ìœ¨ ê²€ì¦
        total_ratio = train_ratio + val_ratio + test_ratio
        if abs(total_ratio - 1.0) > 1e-6:
            raise ValueError(f"ë¶„í•  ë¹„ìœ¨ì˜ í•©ì´ 1.0ì´ ì•„ë‹™ë‹ˆë‹¤: {total_ratio}")
        
        self.train_ratio = train_ratio
        self.val_ratio = val_ratio
        self.test_ratio = test_ratio
        self.random_state = random_state
        
        self.stats = {
            'original_samples': 0,
            'train_samples': 0,
            'val_samples': 0,
            'test_samples': 0,
            'sweetness_bins': 0,
            'split_time': 0.0
        }
        
        logger.info(f"DataSplitter ì´ˆê¸°í™”: Train({train_ratio:.1%}), "
                   f"Val({val_ratio:.1%}), Test({test_ratio:.1%})")
    
    def _create_sweetness_bins(self, sweetness_values: np.ndarray, 
                              n_bins: Optional[int] = None) -> np.ndarray:
        """
        ë‹¹ë„ ê°’ì„ êµ¬ê°„ë³„ë¡œ ë¶„ë¥˜
        
        Args:
            sweetness_values (np.ndarray): ë‹¹ë„ ê°’ ë°°ì—´
            n_bins (Optional[int]): êµ¬ê°„ ìˆ˜ (Noneì´ë©´ ìë™ ê²°ì •)
            
        Returns:
            np.ndarray: êµ¬ê°„ ë ˆì´ë¸” ë°°ì—´
        """
        if n_bins is None:
            # ìƒ˜í”Œ ìˆ˜ì— ë”°ë¼ êµ¬ê°„ ìˆ˜ ìë™ ê²°ì •
            n_samples = len(sweetness_values)
            if n_samples < 50:
                n_bins = 3
            elif n_samples < 100:
                n_bins = 4
            else:
                n_bins = 5
        
        # ë‹¹ë„ ë²”ìœ„ì— ë”°ë¥¸ êµ¬ê°„ ë¶„í• 
        min_sweetness = np.min(sweetness_values)
        max_sweetness = np.max(sweetness_values)
        
        # êµ¬ê°„ ê²½ê³„ ìƒì„±
        bin_edges = np.linspace(min_sweetness, max_sweetness, n_bins + 1)
        
        # êµ¬ê°„ ë ˆì´ë¸” í• ë‹¹
        bin_labels = np.digitize(sweetness_values, bin_edges) - 1
        
        # ë§ˆì§€ë§‰ êµ¬ê°„ ì¡°ì • (ìµœëŒ€ê°’ì´ í¬í•¨ë˜ë„ë¡)
        bin_labels[bin_labels >= n_bins] = n_bins - 1
        
        self.stats['sweetness_bins'] = n_bins
        
        logger.debug(f"ë‹¹ë„ êµ¬ê°„ ìƒì„±: {n_bins}ê°œ êµ¬ê°„, ë²”ìœ„ [{min_sweetness:.1f}, {max_sweetness:.1f}]")
        
        return bin_labels, bin_edges
    
    def split_dataset(self, features_df: pd.DataFrame, 
                     target_column: str = 'sweetness',
                     stratify_bins: Optional[int] = None) -> Dict[str, pd.DataFrame]:
        """
        ë°ì´í„°ì…‹ì„ Train/Validation/Testë¡œ ë¶„í• 
        
        Args:
            features_df (pd.DataFrame): íŠ¹ì§•ê³¼ íƒ€ê²Ÿì„ í¬í•¨í•œ DataFrame
            target_column (str): íƒ€ê²Ÿ ì»¬ëŸ¼ëª… (ê¸°ë³¸ê°’: 'sweetness')
            stratify_bins (Optional[int]): ì¸µí™” ìƒ˜í”Œë§ìš© êµ¬ê°„ ìˆ˜
            
        Returns:
            Dict[str, pd.DataFrame]: {'train': train_df, 'val': val_df, 'test': test_df}
        """
        import time
        start_time = time.time()
        
        logger.info(f"ë°ì´í„°ì…‹ ë¶„í•  ì‹œì‘: {len(features_df)}ê°œ ìƒ˜í”Œ")
        
        # íƒ€ê²Ÿ ì»¬ëŸ¼ í™•ì¸
        if target_column not in features_df.columns:
            raise ValueError(f"íƒ€ê²Ÿ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {target_column}")
        
        self.stats['original_samples'] = len(features_df)
        
        # íŠ¹ì§•ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
        X = features_df.drop(columns=[target_column])
        y = features_df[target_column]
        
        # ì¸µí™” ìƒ˜í”Œë§ì„ ìœ„í•œ êµ¬ê°„ ìƒì„±
        stratify_labels, bin_edges = self._create_sweetness_bins(
            y.values, n_bins=stratify_bins
        )
        
        # 1ë‹¨ê³„: Trainê³¼ (Val+Test) ë¶„í• 
        train_val_ratio = self.val_ratio + self.test_ratio
        
        X_train, X_temp, y_train, y_temp, stratify_train, stratify_temp = train_test_split(
            X, y, stratify_labels,
            test_size=train_val_ratio,
            stratify=stratify_labels,
            random_state=self.random_state
        )
        
        # 2ë‹¨ê³„: (Val+Test)ë¥¼ Valê³¼ Testë¡œ ë¶„í• 
        val_test_ratio = self.val_ratio / train_val_ratio
        
        X_val, X_test, y_val, y_test = train_test_split(
            X_temp, y_temp,
            test_size=(1 - val_test_ratio),
            stratify=stratify_temp,
            random_state=self.random_state
        )
        
        # DataFrame ì¬êµ¬ì„±
        train_df = pd.concat([X_train, y_train], axis=1)
        val_df = pd.concat([X_val, y_val], axis=1)
        test_df = pd.concat([X_test, y_test], axis=1)
        
        # ì¸ë±ìŠ¤ ì¬ì„¤ì •
        train_df = train_df.reset_index(drop=True)
        val_df = val_df.reset_index(drop=True)
        test_df = test_df.reset_index(drop=True)
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        self.stats['train_samples'] = len(train_df)
        self.stats['val_samples'] = len(val_df)
        self.stats['test_samples'] = len(test_df)
        self.stats['split_time'] = time.time() - start_time
        
        split_result = {
            'train': train_df,
            'val': val_df,
            'test': test_df
        }
        
        # ë¶„í•  ê²°ê³¼ ë¡œê·¸
        logger.info(f"ë¶„í•  ì™„ë£Œ:")
        logger.info(f"  - Train: {len(train_df)}ê°œ ({len(train_df)/len(features_df):.1%})")
        logger.info(f"  - Val: {len(val_df)}ê°œ ({len(val_df)/len(features_df):.1%})")
        logger.info(f"  - Test: {len(test_df)}ê°œ ({len(test_df)/len(features_df):.1%})")
        
        return split_result
    
    def validate_split(self, split_data: Dict[str, pd.DataFrame], 
                      target_column: str = 'sweetness') -> Dict:
        """
        ë¶„í•  ê²°ê³¼ ê²€ì¦
        
        Args:
            split_data (Dict[str, pd.DataFrame]): ë¶„í• ëœ ë°ì´í„°ì…‹
            target_column (str): íƒ€ê²Ÿ ì»¬ëŸ¼ëª…
            
        Returns:
            Dict: ê²€ì¦ ê²°ê³¼
        """
        logger.info("ë°ì´í„° ë¶„í•  ê²€ì¦ ì‹œì‘")
        
        validation_result = {
            'split_ratios': {},
            'sweetness_distributions': {},
            'statistical_tests': {},
            'issues': []
        }
        
        total_samples = sum(len(df) for df in split_data.values())
        
        # ë¶„í•  ë¹„ìœ¨ í™•ì¸
        for split_name, df in split_data.items():
            actual_ratio = len(df) / total_samples
            validation_result['split_ratios'][split_name] = {
                'actual': actual_ratio,
                'target': getattr(self, f'{split_name}_ratio'),
                'samples': len(df)
            }
        
        # íƒ€ê²Ÿ ë¶„í¬ ë¹„êµ
        for split_name, df in split_data.items():
            sweetness_values = df[target_column]
            validation_result['sweetness_distributions'][split_name] = {
                'mean': float(sweetness_values.mean()),
                'std': float(sweetness_values.std()),
                'min': float(sweetness_values.min()),
                'max': float(sweetness_values.max()),
                'median': float(sweetness_values.median()),
                'q25': float(sweetness_values.quantile(0.25)),
                'q75': float(sweetness_values.quantile(0.75))
            }
        
        # ë¶„í¬ ê· í˜•ì„± ê²€ì‚¬
        train_mean = validation_result['sweetness_distributions']['train']['mean']
        train_std = validation_result['sweetness_distributions']['train']['std']
        
        for split_name in ['val', 'test']:
            split_mean = validation_result['sweetness_distributions'][split_name]['mean']
            split_std = validation_result['sweetness_distributions'][split_name]['std']
            
            # í‰ê·  ì°¨ì´ ê²€ì‚¬
            mean_diff = abs(split_mean - train_mean)
            if mean_diff > 0.5:  # 0.5 Brix ì´ìƒ ì°¨ì´
                validation_result['issues'].append(
                    f"{split_name} ì„¸íŠ¸ì˜ í‰ê·  ë‹¹ë„ê°€ trainê³¼ {mean_diff:.2f} Brix ì°¨ì´"
                )
            
            # í‘œì¤€í¸ì°¨ ì°¨ì´ ê²€ì‚¬
            std_ratio = split_std / train_std if train_std > 0 else 1.0
            if std_ratio < 0.7 or std_ratio > 1.3:  # 30% ì´ìƒ ì°¨ì´
                validation_result['issues'].append(
                    f"{split_name} ì„¸íŠ¸ì˜ í‘œì¤€í¸ì°¨ê°€ trainê³¼ {abs(1-std_ratio):.1%} ì°¨ì´"
                )
        
        # ë¶„í•  ë¹„ìœ¨ ê²€ì‚¬
        for split_name, ratio_info in validation_result['split_ratios'].items():
            ratio_diff = abs(ratio_info['actual'] - ratio_info['target'])
            if ratio_diff > 0.02:  # 2% ì´ìƒ ì°¨ì´
                validation_result['issues'].append(
                    f"{split_name} ì„¸íŠ¸ ë¹„ìœ¨ì´ ëª©í‘œì™€ {ratio_diff:.1%} ì°¨ì´"
                )
        
        # ìµœì†Œ ìƒ˜í”Œ ìˆ˜ ê²€ì‚¬
        min_samples_required = 10  # ìµœì†Œ 10ê°œ ìƒ˜í”Œ
        for split_name, df in split_data.items():
            if len(df) < min_samples_required:
                validation_result['issues'].append(
                    f"{split_name} ì„¸íŠ¸ì˜ ìƒ˜í”Œ ìˆ˜ê°€ ë¶€ì¡±: {len(df)}ê°œ < {min_samples_required}ê°œ"
                )
        
        # ì „ì²´ ê²€ì¦ ê²°ê³¼
        if len(validation_result['issues']) == 0:
            validation_result['overall_quality'] = 'excellent'
        elif len(validation_result['issues']) <= 2:
            validation_result['overall_quality'] = 'good'
        else:
            validation_result['overall_quality'] = 'poor'
        
        logger.info(f"ë¶„í•  ê²€ì¦ ì™„ë£Œ: {validation_result['overall_quality']}")
        if validation_result['issues']:
            logger.warning(f"ë°œê²¬ëœ ì´ìŠˆ: {validation_result['issues']}")
        
        return validation_result
    
    def save_splits(self, split_data: Dict[str, pd.DataFrame], 
                   output_dir: Union[str, Path]) -> Dict[str, str]:
        """
        ë¶„í• ëœ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            split_data (Dict[str, pd.DataFrame]): ë¶„í• ëœ ë°ì´í„°ì…‹
            output_dir (Union[str, Path]): ì¶œë ¥ ë””ë ‰í† ë¦¬
            
        Returns:
            Dict[str, str]: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œë“¤
        """
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        saved_files = {}
        
        for split_name, df in split_data.items():
            file_path = output_dir / f"{split_name}.csv"
            df.to_csv(file_path, index=False)
            saved_files[split_name] = str(file_path)
            logger.info(f"{split_name} ì„¸íŠ¸ ì €ì¥: {file_path} ({len(df)}ê°œ ìƒ˜í”Œ)")
        
        # ë¶„í•  ì •ë³´ ì €ì¥
        split_info = {
            'train_ratio': self.train_ratio,
            'val_ratio': self.val_ratio,
            'test_ratio': self.test_ratio,
            'random_state': self.random_state,
            'total_samples': sum(len(df) for df in split_data.values()),
            'train_samples': len(split_data['train']),
            'val_samples': len(split_data['val']),
            'test_samples': len(split_data['test'])
        }
        
        info_path = output_dir / "split_info.txt"
        with open(info_path, 'w', encoding='utf-8') as f:
            f.write("ğŸ‰ ìˆ˜ë°• ë°ì´í„°ì…‹ ë¶„í•  ì •ë³´\n")
            f.write("=" * 40 + "\n\n")
            for key, value in split_info.items():
                f.write(f"{key}: {value}\n")
        
        saved_files['split_info'] = str(info_path)
        logger.info(f"ë¶„í•  ì •ë³´ ì €ì¥: {info_path}")
        
        return saved_files
    
    def visualize_split_distribution(self, split_data: Dict[str, pd.DataFrame], 
                                    target_column: str = 'sweetness',
                                    output_path: Optional[Union[str, Path]] = None) -> None:
        """
        ë¶„í• ëœ ë°ì´í„°ì˜ ë‹¹ë„ ë¶„í¬ ì‹œê°í™”
        
        Args:
            split_data (Dict[str, pd.DataFrame]): ë¶„í• ëœ ë°ì´í„°ì…‹
            target_column (str): íƒ€ê²Ÿ ì»¬ëŸ¼ëª…
            output_path (Optional[Union[str, Path]]): ì €ì¥í•  ì´ë¯¸ì§€ ê²½ë¡œ
        """
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('ğŸ‰ ìˆ˜ë°• ë°ì´í„°ì…‹ ë¶„í•  ê²°ê³¼', fontsize=16, fontweight='bold')
        
        # ìƒ‰ìƒ ì„¤ì •
        colors = {'train': '#2E8B57', 'val': '#FF6347', 'test': '#4682B4'}
        
        # 1. íˆìŠ¤í† ê·¸ë¨ ë¹„êµ
        ax1 = axes[0, 0]
        for split_name, df in split_data.items():
            sweetness_values = df[target_column]
            ax1.hist(sweetness_values, bins=15, alpha=0.7, 
                    label=f'{split_name.title()} (n={len(df)})',
                    color=colors[split_name])
        
        ax1.set_xlabel('ë‹¹ë„ (Brix)')
        ax1.set_ylabel('ìƒ˜í”Œ ìˆ˜')
        ax1.set_title('ë‹¹ë„ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. ë°•ìŠ¤ í”Œë¡¯
        ax2 = axes[0, 1]
        box_data = [split_data[name][target_column] for name in ['train', 'val', 'test']]
        box_plot = ax2.boxplot(box_data, labels=['Train', 'Val', 'Test'], 
                              patch_artist=True)
        
        for patch, color in zip(box_plot['boxes'], [colors['train'], colors['val'], colors['test']]):
            patch.set_facecolor(color)
            patch.set_alpha(0.7)
        
        ax2.set_ylabel('ë‹¹ë„ (Brix)')
        ax2.set_title('ë‹¹ë„ ë¶„í¬ ë°•ìŠ¤ í”Œë¡¯')
        ax2.grid(True, alpha=0.3)
        
        # 3. ìƒ˜í”Œ ìˆ˜ ë¹„êµ
        ax3 = axes[1, 0]
        split_names = list(split_data.keys())
        sample_counts = [len(split_data[name]) for name in split_names]
        bars = ax3.bar(split_names, sample_counts, 
                      color=[colors[name] for name in split_names], alpha=0.8)
        
        # ë°” ìœ„ì— ìˆ«ì í‘œì‹œ
        for bar, count in zip(bars, sample_counts):
            ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                    str(count), ha='center', va='bottom', fontweight='bold')
        
        ax3.set_ylabel('ìƒ˜í”Œ ìˆ˜')
        ax3.set_title('ì„¸íŠ¸ë³„ ìƒ˜í”Œ ìˆ˜')
        ax3.grid(True, alpha=0.3)
        
        # 4. í†µê³„ ì •ë³´ í…Œì´ë¸”
        ax4 = axes[1, 1]
        ax4.axis('off')
        
        # í†µê³„ ë°ì´í„° ì¤€ë¹„
        stats_data = []
        for split_name, df in split_data.items():
            sweetness_values = df[target_column]
            stats_data.append([
                split_name.title(),
                len(df),
                f"{sweetness_values.mean():.2f}",
                f"{sweetness_values.std():.2f}",
                f"{sweetness_values.min():.1f}-{sweetness_values.max():.1f}"
            ])
        
        # í…Œì´ë¸” ìƒì„±
        table = ax4.table(cellText=stats_data,
                         colLabels=['ì„¸íŠ¸', 'ìƒ˜í”Œ ìˆ˜', 'í‰ê· ', 'í‘œì¤€í¸ì°¨', 'ë²”ìœ„'],
                         cellLoc='center',
                         loc='center')
        
        table.auto_set_font_size(False)
        table.set_fontsize(10)
        table.scale(1, 2)
        
        # í—¤ë” ìŠ¤íƒ€ì¼ë§
        for i in range(5):
            table[(0, i)].set_facecolor('#E6E6FA')
            table[(0, i)].set_text_props(weight='bold')
        
        # í–‰ ìƒ‰ìƒ ì„¤ì •
        for i, split_name in enumerate(['train', 'val', 'test']):
            for j in range(5):
                table[(i+1, j)].set_facecolor(colors[split_name])
                table[(i+1, j)].set_alpha(0.3)
        
        ax4.set_title('ë¶„í•  í†µê³„ ìš”ì•½')
        
        plt.tight_layout()
        
        # ì´ë¯¸ì§€ ì €ì¥
        if output_path:
            plt.savefig(output_path, dpi=300, bbox_inches='tight')
            logger.info(f"ë¶„í•  ì‹œê°í™” ì €ì¥: {output_path}")
        
        plt.show()
    
    def get_stats(self) -> Dict:
        """í†µê³„ ì •ë³´ ë°˜í™˜"""
        return self.stats.copy()
    
    def reset_stats(self):
        """í†µê³„ ì •ë³´ ì´ˆê¸°í™”"""
        self.stats = {
            'original_samples': 0,
            'train_samples': 0,
            'val_samples': 0,
            'test_samples': 0,
            'sweetness_bins': 0,
            'split_time': 0.0
        }
        logger.info("DataSplitter í†µê³„ ì •ë³´ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def __repr__(self) -> str:
        return (f"DataSplitter(train={self.train_ratio:.1%}, "
                f"val={self.val_ratio:.1%}, test={self.test_ratio:.1%}, "
                f"random_state={self.random_state})")


# í¸ì˜ í•¨ìˆ˜ë“¤
def split_watermelon_dataset(features_csv_path: Union[str, Path],
                            output_dir: Union[str, Path],
                            train_ratio: float = 0.7,
                            val_ratio: float = 0.15,
                            test_ratio: float = 0.15,
                            random_state: int = 42) -> Dict:
    """
    ìˆ˜ë°• ë°ì´í„°ì…‹ ë¶„í• ì„ ìœ„í•œ í¸ì˜ í•¨ìˆ˜
    
    Args:
        features_csv_path (Union[str, Path]): íŠ¹ì§• CSV íŒŒì¼ ê²½ë¡œ
        output_dir (Union[str, Path]): ì¶œë ¥ ë””ë ‰í† ë¦¬
        train_ratio (float): í›ˆë ¨ ì„¸íŠ¸ ë¹„ìœ¨
        val_ratio (float): ê²€ì¦ ì„¸íŠ¸ ë¹„ìœ¨
        test_ratio (float): í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¹„ìœ¨
        random_state (int): ëœë¤ ì‹œë“œ
        
    Returns:
        Dict: ë¶„í•  ê²°ê³¼ ì •ë³´
    """
    # ë°ì´í„° ë¡œë“œ
    features_df = pd.read_csv(features_csv_path)
    
    # DataSplitter ìƒì„± ë° ë¶„í• 
    splitter = DataSplitter(
        train_ratio=train_ratio,
        val_ratio=val_ratio,
        test_ratio=test_ratio,
        random_state=random_state
    )
    
    split_data = splitter.split_dataset(features_df)
    
    # ë¶„í•  ê²€ì¦
    validation_result = splitter.validate_split(split_data)
    
    # íŒŒì¼ ì €ì¥
    saved_files = splitter.save_splits(split_data, output_dir)
    
    # ì‹œê°í™” ì €ì¥
    viz_path = Path(output_dir) / "split_distribution.png"
    splitter.visualize_split_distribution(split_data, output_path=viz_path)
    
    return {
        'split_data': split_data,
        'validation_result': validation_result,
        'saved_files': saved_files,
        'stats': splitter.get_stats()
    }


if __name__ == "__main__":
    # ì‚¬ìš© ì˜ˆì œ
    from pathlib import Path
    import numpy as np
    
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
    project_root = Path(__file__).parent.parent.parent
    
    print(f"\nğŸ“Š DataSplitter í…ŒìŠ¤íŠ¸")
    
    # í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ìƒì„±
    np.random.seed(42)
    n_samples = 100
    n_features = 51
    
    # ê°€ì§œ íŠ¹ì§• ë°ì´í„° ìƒì„±
    features = np.random.randn(n_samples, n_features)
    feature_names = [f'feature_{i+1}' for i in range(n_features)]
    
    # ê°€ì§œ ë‹¹ë„ ë°ì´í„° ìƒì„± (9-12 Brix ë²”ìœ„)
    sweetness = np.random.normal(10.5, 1.0, n_samples)
    sweetness = np.clip(sweetness, 9.0, 12.0)
    
    # DataFrame ìƒì„±
    test_df = pd.DataFrame(features, columns=feature_names)
    test_df['sweetness'] = sweetness
    
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±: {test_df.shape}")
    print(f"ë‹¹ë„ ë²”ìœ„: {sweetness.min():.1f} - {sweetness.max():.1f} Brix")
    
    # DataSplitter ìƒì„±
    splitter = DataSplitter(
        train_ratio=0.7,
        val_ratio=0.15,
        test_ratio=0.15,
        random_state=42
    )
    
    # ë°ì´í„° ë¶„í• 
    split_data = splitter.split_dataset(test_df)
    
    print(f"\në¶„í•  ê²°ê³¼:")
    for split_name, df in split_data.items():
        sweetness_stats = df['sweetness']
        print(f"  - {split_name.title()}: {len(df)}ê°œ ìƒ˜í”Œ, "
              f"ë‹¹ë„ í‰ê·  {sweetness_stats.mean():.2f}Â±{sweetness_stats.std():.2f}")
    
    # ë¶„í•  ê²€ì¦
    validation_result = splitter.validate_split(split_data)
    print(f"\nê²€ì¦ ê²°ê³¼: {validation_result['overall_quality']}")
    if validation_result['issues']:
        print(f"ì´ìŠˆ: {validation_result['issues']}")
    
    # ì„ì‹œ ë””ë ‰í† ë¦¬ì— ì €ì¥
    test_output_dir = project_root / "data" / "splits" / "test"
    saved_files = splitter.save_splits(split_data, test_output_dir)
    
    print(f"\nì €ì¥ëœ íŒŒì¼:")
    for split_name, file_path in saved_files.items():
        print(f"  - {split_name}: {file_path}")
    
    # ì‹œê°í™” (ì„ íƒì‚¬í•­)
    try:
        viz_path = test_output_dir / "test_split_distribution.png"
        splitter.visualize_split_distribution(split_data, output_path=viz_path)
        print(f"ì‹œê°í™” ì €ì¥: {viz_path}")
    except Exception as e:
        print(f"ì‹œê°í™” ì‹¤íŒ¨ (matplotlib í™˜ê²½ ì´ìŠˆì¼ ìˆ˜ ìˆìŒ): {e}")
    
    # í†µê³„ ì •ë³´
    stats = splitter.get_stats()
    print(f"\nSplitter í†µê³„: {stats}") 