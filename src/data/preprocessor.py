"""
ğŸ‰ ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ML í”„ë¡œì íŠ¸ - ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ëª¨ë“ˆ
AudioPreprocessor í´ë˜ìŠ¤: ì˜¤ë””ì˜¤ ì‹ í˜¸ì˜ ì „ì²˜ë¦¬ (ë¬µìŒ ì œê±°, ì •ê·œí™”, í•„í„°ë§ ë“±)
"""

import logging
from typing import Tuple, Optional, Union
import numpy as np
import librosa
import scipy.signal
from pathlib import Path
import yaml

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class AudioPreprocessor:
    """
    ì˜¤ë””ì˜¤ ì‹ í˜¸ ì „ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤
    
    ê¸°ëŠ¥:
    - ë¬µìŒ êµ¬ê°„ ì œê±° (trimming)
    - ì‹ í˜¸ ì •ê·œí™” (normalization)
    - ë…¸ì´ì¦ˆ í•„í„°ë§ (filtering)
    - í’ˆì§ˆ ê²€ì¦ (quality validation)
    """
    
    def __init__(self, config_path: Optional[Union[str, Path]] = None):
        """
        AudioPreprocessor ì´ˆê¸°í™”
        
        Args:
            config_path (Optional[Union[str, Path]]): ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        self.config = self._load_config(config_path)
        self.stats = {
            'processed_files': 0,
            'trim_applied': 0,
            'normalize_applied': 0,
            'filter_applied': 0,
            'quality_issues': 0
        }
        
        logger.info("AudioPreprocessor ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _load_config(self, config_path: Optional[Union[str, Path]]) -> dict:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        if config_path is None:
            # ê¸°ë³¸ ì„¤ì • ë°˜í™˜
            return self._get_default_config()
        
        try:
            config_path = Path(config_path)
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            logger.info(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì„±ê³µ: {config_path}")
            return config
        except Exception as e:
            logger.warning(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ ì„¤ì • ì‚¬ìš©: {e}")
            return self._get_default_config()
    
    def _get_default_config(self) -> dict:
        """ê¸°ë³¸ ì„¤ì • ë°˜í™˜"""
        return {
            'audio': {
                'sample_rate': 16000,
                'trim': {
                    'enabled': True,
                    'top_db': 20,
                    'frame_length': 2048,
                    'hop_length': 512
                },
                'normalize': {
                    'enabled': True,
                    'method': 'peak',
                    'target_level': 0.9
                },
                'filter_noise': {
                    'enabled': False,
                    'low_freq': 80,
                    'high_freq': 8000
                }
            },
            'quality_check': {
                'min_duration': 0.1,
                'max_duration': 10.0,
                'check_clipping': True,
                'check_silence': True,
                'silence_threshold': -60,
                'max_silence_ratio': 0.8
            }
        }
    
    def trim_silence(self, audio_data: np.ndarray, 
                    sample_rate: int,
                    top_db: Optional[int] = None,
                    frame_length: Optional[int] = None,
                    hop_length: Optional[int] = None) -> Tuple[np.ndarray, dict]:
        """
        ë¬µìŒ êµ¬ê°„ ì œê±°
        
        Args:
            audio_data (np.ndarray): ì…ë ¥ ì˜¤ë””ì˜¤ ë°ì´í„°
            sample_rate (int): ìƒ˜í”Œë§ ë ˆì´íŠ¸
            top_db (Optional[int]): dB ì„ê³„ê°’
            frame_length (Optional[int]): í”„ë ˆì„ ê¸¸ì´
            hop_length (Optional[int]): í™‰ ê¸¸ì´
            
        Returns:
            Tuple[np.ndarray, dict]: (ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ ë°ì´í„°, ì²˜ë¦¬ ì •ë³´)
        """
        if not self.config['audio']['trim']['enabled']:
            return audio_data, {'trimmed': False, 'original_length': len(audio_data)}
        
        # íŒŒë¼ë¯¸í„° ì„¤ì •
        top_db = top_db or self.config['audio']['trim']['top_db']
        frame_length = frame_length or self.config['audio']['trim']['frame_length']
        hop_length = hop_length or self.config['audio']['trim']['hop_length']
        
        original_length = len(audio_data)
        
        try:
            # librosaì˜ trim í•¨ìˆ˜ ì‚¬ìš©
            trimmed_audio, indices = librosa.effects.trim(
                audio_data,
                top_db=top_db,
                frame_length=frame_length,
                hop_length=hop_length
            )
            
            trim_info = {
                'trimmed': True,
                'original_length': original_length,
                'trimmed_length': len(trimmed_audio),
                'removed_samples': original_length - len(trimmed_audio),
                'removed_ratio': (original_length - len(trimmed_audio)) / original_length,
                'start_index': indices[0],
                'end_index': indices[1],
                'top_db': top_db
            }
            
            self.stats['trim_applied'] += 1
            logger.debug(f"ë¬µìŒ ì œê±° ì™„ë£Œ: {original_length} -> {len(trimmed_audio)} samples "
                        f"({trim_info['removed_ratio']:.1%} ì œê±°)")
            
            return trimmed_audio, trim_info
            
        except Exception as e:
            logger.warning(f"ë¬µìŒ ì œê±° ì‹¤íŒ¨, ì›ë³¸ ë°˜í™˜: {e}")
            return audio_data, {
                'trimmed': False,
                'original_length': original_length,
                'error': str(e)
            }
    
    def normalize_audio(self, audio_data: np.ndarray, 
                       method: Optional[str] = None,
                       target_level: Optional[float] = None) -> Tuple[np.ndarray, dict]:
        """
        ì˜¤ë””ì˜¤ ì‹ í˜¸ ì •ê·œí™”
        
        Args:
            audio_data (np.ndarray): ì…ë ¥ ì˜¤ë””ì˜¤ ë°ì´í„°
            method (Optional[str]): ì •ê·œí™” ë°©ë²• ('peak' ë˜ëŠ” 'rms')
            target_level (Optional[float]): ëª©í‘œ ë ˆë²¨ (0-1)
            
        Returns:
            Tuple[np.ndarray, dict]: (ì •ê·œí™”ëœ ì˜¤ë””ì˜¤ ë°ì´í„°, ì •ê·œí™” ì •ë³´)
        """
        if not self.config['audio']['normalize']['enabled']:
            return audio_data, {'normalized': False}
        
        # íŒŒë¼ë¯¸í„° ì„¤ì •
        method = method or self.config['audio']['normalize']['method']
        target_level = target_level or self.config['audio']['normalize']['target_level']
        
        original_peak = np.max(np.abs(audio_data))
        original_rms = np.sqrt(np.mean(audio_data ** 2))
        
        try:
            if method == 'peak':
                # í”¼í¬ ì •ê·œí™”
                if original_peak > 0:
                    normalized_audio = audio_data * (target_level / original_peak)
                else:
                    normalized_audio = audio_data
                    
            elif method == 'rms':
                # RMS ì •ê·œí™”
                if original_rms > 0:
                    normalized_audio = audio_data * (target_level / original_rms)
                    # í´ë¦¬í•‘ ë°©ì§€
                    max_val = np.max(np.abs(normalized_audio))
                    if max_val > 1.0:
                        normalized_audio = normalized_audio / max_val
                else:
                    normalized_audio = audio_data
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì •ê·œí™” ë°©ë²•: {method}")
            
            new_peak = np.max(np.abs(normalized_audio))
            new_rms = np.sqrt(np.mean(normalized_audio ** 2))
            
            normalize_info = {
                'normalized': True,
                'method': method,
                'target_level': target_level,
                'original_peak': original_peak,
                'original_rms': original_rms,
                'new_peak': new_peak,
                'new_rms': new_rms,
                'peak_ratio': new_peak / original_peak if original_peak > 0 else 1.0,
                'rms_ratio': new_rms / original_rms if original_rms > 0 else 1.0
            }
            
            self.stats['normalize_applied'] += 1
            logger.debug(f"ì •ê·œí™” ì™„ë£Œ ({method}): peak {original_peak:.3f} -> {new_peak:.3f}, "
                        f"RMS {original_rms:.3f} -> {new_rms:.3f}")
            
            return normalized_audio, normalize_info
            
        except Exception as e:
            logger.warning(f"ì •ê·œí™” ì‹¤íŒ¨, ì›ë³¸ ë°˜í™˜: {e}")
            return audio_data, {
                'normalized': False,
                'error': str(e)
            }
    
    def apply_bandpass_filter(self, audio_data: np.ndarray, 
                             sample_rate: int,
                             low_freq: Optional[int] = None,
                             high_freq: Optional[int] = None) -> Tuple[np.ndarray, dict]:
        """
        ëŒ€ì—­í†µê³¼ í•„í„° ì ìš©
        
        Args:
            audio_data (np.ndarray): ì…ë ¥ ì˜¤ë””ì˜¤ ë°ì´í„°
            sample_rate (int): ìƒ˜í”Œë§ ë ˆì´íŠ¸
            low_freq (Optional[int]): ì €ì£¼íŒŒ ì»·ì˜¤í”„
            high_freq (Optional[int]): ê³ ì£¼íŒŒ ì»·ì˜¤í”„
            
        Returns:
            Tuple[np.ndarray, dict]: (í•„í„°ë§ëœ ì˜¤ë””ì˜¤ ë°ì´í„°, í•„í„° ì •ë³´)
        """
        if not self.config['audio']['filter_noise']['enabled']:
            return audio_data, {'filtered': False}
        
        # íŒŒë¼ë¯¸í„° ì„¤ì •
        low_freq = low_freq or self.config['audio']['filter_noise']['low_freq']
        high_freq = high_freq or self.config['audio']['filter_noise']['high_freq']
        
        try:
            # Nyquist ì£¼íŒŒìˆ˜
            nyquist = sample_rate / 2
            
            # ì •ê·œí™”ëœ ì»·ì˜¤í”„ ì£¼íŒŒìˆ˜
            low_norm = low_freq / nyquist
            high_norm = min(high_freq / nyquist, 0.99)  # Nyquist ë¯¸ë§Œìœ¼ë¡œ ì œí•œ
            
            # Butterworth í•„í„° ê³„ìˆ˜ ê³„ì‚°
            filter_order = 4
            b, a = scipy.signal.butter(filter_order, [low_norm, high_norm], btype='band')
            
            # í•„í„° ì ìš©
            filtered_audio = scipy.signal.filtfilt(b, a, audio_data)
            
            filter_info = {
                'filtered': True,
                'filter_type': 'bandpass',
                'filter_order': filter_order,
                'low_freq': low_freq,
                'high_freq': high_freq,
                'sample_rate': sample_rate,
                'low_norm': low_norm,
                'high_norm': high_norm
            }
            
            self.stats['filter_applied'] += 1
            logger.debug(f"ëŒ€ì—­í†µê³¼ í•„í„° ì ìš©: {low_freq}-{high_freq} Hz")
            
            return filtered_audio, filter_info
            
        except Exception as e:
            logger.warning(f"í•„í„°ë§ ì‹¤íŒ¨, ì›ë³¸ ë°˜í™˜: {e}")
            return audio_data, {
                'filtered': False,
                'error': str(e)
            }
    
    def check_audio_quality(self, audio_data: np.ndarray, 
                           sample_rate: int) -> dict:
        """
        ì˜¤ë””ì˜¤ í’ˆì§ˆ ê²€ì‚¬
        
        Args:
            audio_data (np.ndarray): ì˜¤ë””ì˜¤ ë°ì´í„°
            sample_rate (int): ìƒ˜í”Œë§ ë ˆì´íŠ¸
            
        Returns:
            dict: í’ˆì§ˆ ê²€ì‚¬ ê²°ê³¼
        """
        quality_config = self.config['quality_check']
        
        duration = len(audio_data) / sample_rate
        peak_amplitude = np.max(np.abs(audio_data))
        rms_amplitude = np.sqrt(np.mean(audio_data ** 2))
        
        # ê¸°ë³¸ í’ˆì§ˆ ì§€í‘œ
        quality_result = {
            'duration': duration,
            'peak_amplitude': peak_amplitude,
            'rms_amplitude': rms_amplitude,
            'dynamic_range': 20 * np.log10(peak_amplitude / (rms_amplitude + 1e-10)),
            'issues': []
        }
        
        # ê¸¸ì´ ê²€ì‚¬
        if duration < quality_config['min_duration']:
            quality_result['issues'].append(f"ë„ˆë¬´ ì§§ìŒ: {duration:.2f}s < {quality_config['min_duration']}s")
        if duration > quality_config['max_duration']:
            quality_result['issues'].append(f"ë„ˆë¬´ ê¹€: {duration:.2f}s > {quality_config['max_duration']}s")
        
        # í´ë¦¬í•‘ ê²€ì‚¬
        if quality_config['check_clipping']:
            clipping_ratio = np.sum(np.abs(audio_data) > 0.99) / len(audio_data)
            quality_result['clipping_ratio'] = clipping_ratio
            if clipping_ratio > 0.01:  # 1% ì´ìƒ í´ë¦¬í•‘
                quality_result['issues'].append(f"í´ë¦¬í•‘ ê°ì§€: {clipping_ratio:.2%}")
        
        # ë¬´ìŒ ê²€ì‚¬
        if quality_config['check_silence']:
            silence_threshold_linear = 10 ** (quality_config['silence_threshold'] / 20)
            silence_ratio = np.sum(np.abs(audio_data) < silence_threshold_linear) / len(audio_data)
            quality_result['silence_ratio'] = silence_ratio
            if silence_ratio > quality_config['max_silence_ratio']:
                quality_result['issues'].append(f"ê³¼ë„í•œ ë¬´ìŒ: {silence_ratio:.2%}")
        
        # SNR ì¶”ì • (ê°„ë‹¨í•œ ë°©ë²•)
        if rms_amplitude > 0:
            noise_floor = np.percentile(np.abs(audio_data), 10)  # í•˜ìœ„ 10%ë¥¼ ë…¸ì´ì¦ˆë¡œ ê°€ì •
            snr_estimate = 20 * np.log10(rms_amplitude / (noise_floor + 1e-10))
            quality_result['snr_estimate'] = snr_estimate
            
            if snr_estimate < 20:  # 20dB ë¯¸ë§Œ
                quality_result['issues'].append(f"ë‚®ì€ SNR: {snr_estimate:.1f}dB")
        
        # í’ˆì§ˆ ë“±ê¸‰ ê²°ì •
        if len(quality_result['issues']) == 0:
            quality_result['quality_grade'] = 'excellent'
        elif len(quality_result['issues']) <= 2:
            quality_result['quality_grade'] = 'good'
        elif len(quality_result['issues']) <= 4:
            quality_result['quality_grade'] = 'fair'
        else:
            quality_result['quality_grade'] = 'poor'
        
        if quality_result['issues']:
            self.stats['quality_issues'] += 1
        
        return quality_result
    
    def preprocess_audio(self, audio_data: np.ndarray, 
                        sample_rate: int) -> Tuple[np.ndarray, dict]:
        """
        ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            audio_data (np.ndarray): ì…ë ¥ ì˜¤ë””ì˜¤ ë°ì´í„°
            sample_rate (int): ìƒ˜í”Œë§ ë ˆì´íŠ¸
            
        Returns:
            Tuple[np.ndarray, dict]: (ì „ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ ë°ì´í„°, ì „ì²˜ë¦¬ ì •ë³´)
        """
        processing_info = {
            'original_shape': audio_data.shape,
            'sample_rate': sample_rate,
            'steps': []
        }
        
        processed_audio = audio_data.copy()
        
        # 1. í’ˆì§ˆ ê²€ì‚¬ (ì „ì²˜ë¦¬ ì „)
        pre_quality = self.check_audio_quality(processed_audio, sample_rate)
        processing_info['pre_quality'] = pre_quality
        
        # 2. ë¬µìŒ ì œê±°
        processed_audio, trim_info = self.trim_silence(processed_audio, sample_rate)
        processing_info['steps'].append(('trim', trim_info))
        
        # 3. í•„í„°ë§ (ë…¸ì´ì¦ˆ ì œê±°)
        processed_audio, filter_info = self.apply_bandpass_filter(processed_audio, sample_rate)
        processing_info['steps'].append(('filter', filter_info))
        
        # 4. ì •ê·œí™”
        processed_audio, normalize_info = self.normalize_audio(processed_audio)
        processing_info['steps'].append(('normalize', normalize_info))
        
        # 5. í’ˆì§ˆ ê²€ì‚¬ (ì „ì²˜ë¦¬ í›„)
        post_quality = self.check_audio_quality(processed_audio, sample_rate)
        processing_info['post_quality'] = post_quality
        
        # ìµœì¢… ì •ë³´ ì—…ë°ì´íŠ¸
        processing_info['final_shape'] = processed_audio.shape
        processing_info['duration_change'] = (len(processed_audio) - len(audio_data)) / sample_rate
        processing_info['quality_improvement'] = len(pre_quality['issues']) - len(post_quality['issues'])
        
        self.stats['processed_files'] += 1
        
        logger.debug(f"ì „ì²˜ë¦¬ ì™„ë£Œ: {audio_data.shape} -> {processed_audio.shape}, "
                    f"í’ˆì§ˆ ê°œì„ : {processing_info['quality_improvement']}ê°œ ì´ìŠˆ í•´ê²°")
        
        return processed_audio, processing_info
    
    def get_stats(self) -> dict:
        """ì „ì²˜ë¦¬ í†µê³„ ì •ë³´ ë°˜í™˜"""
        return self.stats.copy()
    
    def reset_stats(self):
        """í†µê³„ ì •ë³´ ì´ˆê¸°í™”"""
        self.stats = {
            'processed_files': 0,
            'trim_applied': 0,
            'normalize_applied': 0,
            'filter_applied': 0,
            'quality_issues': 0
        }
        logger.info("AudioPreprocessor í†µê³„ ì •ë³´ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def __repr__(self) -> str:
        return f"AudioPreprocessor(processed_files={self.stats['processed_files']})"


# í¸ì˜ í•¨ìˆ˜ë“¤
def preprocess_audio_file(audio_data: np.ndarray, 
                         sample_rate: int,
                         config_path: Optional[Union[str, Path]] = None) -> Tuple[np.ndarray, dict]:
    """
    ë‹¨ì¼ ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ í¸ì˜ í•¨ìˆ˜
    
    Args:
        audio_data (np.ndarray): ì˜¤ë””ì˜¤ ë°ì´í„°
        sample_rate (int): ìƒ˜í”Œë§ ë ˆì´íŠ¸
        config_path (Optional[Union[str, Path]]): ì„¤ì • íŒŒì¼ ê²½ë¡œ
        
    Returns:
        Tuple[np.ndarray, dict]: (ì „ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ ë°ì´í„°, ì „ì²˜ë¦¬ ì •ë³´)
    """
    preprocessor = AudioPreprocessor(config_path=config_path)
    return preprocessor.preprocess_audio(audio_data, sample_rate)


if __name__ == "__main__":
    # ì‚¬ìš© ì˜ˆì œ
    from pathlib import Path
    import sys
    
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
    project_root = Path(__file__).parent.parent.parent
    config_path = project_root / "configs" / "preprocessing.yaml"
    
    # AudioPreprocessor í…ŒìŠ¤íŠ¸
    preprocessor = AudioPreprocessor(config_path=config_path)
    
    # í…ŒìŠ¤íŠ¸ìš© ì‹ í˜¸ ìƒì„±
    sample_rate = 16000
    duration = 2.0
    t = np.linspace(0, duration, int(sample_rate * duration))
    
    # ìˆ˜ë°• ì†Œë¦¬ ì‹œë®¬ë ˆì´ì…˜ (440Hz ê¸°ë³¸ ì£¼íŒŒìˆ˜ + í•˜ëª¨ë‹‰ìŠ¤ + ë…¸ì´ì¦ˆ)
    fundamental = 440
    test_signal = (
        0.5 * np.sin(2 * np.pi * fundamental * t) +          # ê¸°ë³¸ ì£¼íŒŒìˆ˜
        0.3 * np.sin(2 * np.pi * fundamental * 2 * t) +      # 2ì°¨ í•˜ëª¨ë‹‰
        0.2 * np.sin(2 * np.pi * fundamental * 3 * t) +      # 3ì°¨ í•˜ëª¨ë‹‰
        0.1 * np.random.normal(0, 0.1, len(t))               # ë…¸ì´ì¦ˆ
    )
    
    # ì•ë’¤ì— ë¬´ìŒ êµ¬ê°„ ì¶”ê°€
    silence_samples = int(0.2 * sample_rate)  # 0.2ì´ˆ ë¬´ìŒ
    silence = np.zeros(silence_samples)
    test_signal_with_silence = np.concatenate([silence, test_signal, silence])
    
    print(f"\nğŸ”§ AudioPreprocessor í…ŒìŠ¤íŠ¸")
    print(f"ì›ë³¸ ì‹ í˜¸: {test_signal_with_silence.shape}, ê¸¸ì´: {len(test_signal_with_silence)/sample_rate:.2f}ì´ˆ")
    
    # ì „ì²˜ë¦¬ ì‹¤í–‰
    processed_signal, processing_info = preprocessor.preprocess_audio(
        test_signal_with_silence, sample_rate
    )
    
    print(f"ì²˜ë¦¬ëœ ì‹ í˜¸: {processed_signal.shape}, ê¸¸ì´: {len(processed_signal)/sample_rate:.2f}ì´ˆ")
    print(f"ê¸¸ì´ ë³€í™”: {processing_info['duration_change']:.3f}ì´ˆ")
    print(f"í’ˆì§ˆ ê°œì„ : {processing_info['quality_improvement']}ê°œ ì´ìŠˆ í•´ê²°")
    
    # ê° ë‹¨ê³„ë³„ ì •ë³´ ì¶œë ¥
    for step_name, step_info in processing_info['steps']:
        if step_info.get('trimmed', False):
            print(f"  - ë¬µìŒ ì œê±°: {step_info['removed_ratio']:.1%} ì œê±°")
        elif step_info.get('filtered', False):
            print(f"  - í•„í„°ë§: {step_info['low_freq']}-{step_info['high_freq']} Hz")
        elif step_info.get('normalized', False):
            print(f"  - ì •ê·œí™”: {step_info['method']}, peak {step_info['original_peak']:.3f} -> {step_info['new_peak']:.3f}")
    
    # í’ˆì§ˆ ì •ë³´ ì¶œë ¥
    post_quality = processing_info['post_quality']
    print(f"ìµœì¢… í’ˆì§ˆ: {post_quality['quality_grade']}")
    if post_quality['issues']:
        print(f"  ë‚¨ì€ ì´ìŠˆ: {post_quality['issues']}")
    
    # í†µê³„ ì •ë³´ ì¶œë ¥
    stats = preprocessor.get_stats()
    print(f"ì²˜ë¦¬ í†µê³„: {stats}") 