"""
ğŸ‰ ê²°ê³¼ ì‹œê°í™” ëª¨ë“ˆ
ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸ë“¤ì˜ í¬ê´„ì ì¸ ì‹œê°í™” ë° ê²°ê³¼ ë¶„ì„

Author: Watermelon ML Team
Date: 2025-01-15
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from typing import Dict, Any, List, Tuple, Optional, Union
from pathlib import Path
import logging
from datetime import datetime
import platform
from matplotlib import font_manager, rc

if platform.system() == 'Darwin':  # macOS
    rc('font', family='AppleGothic')
elif platform.system() == 'Windows':
    rc('font', family='Malgun Gothic')
else:  # Linux ë“±
    rc('font', family='NanumGothic')

plt.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤ ê¹¨ì§ ë°©ì§€

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ResultVisualizer:
    """
    ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸ ê²°ê³¼ì˜ í¬ê´„ì ì¸ ì‹œê°í™” í´ë˜ìŠ¤
    
    ê¸°ëŠ¥:
    - ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸
    - ì˜ˆì¸¡ ì •í™•ë„ ì‹œê°í™”
    - ì”ì°¨ ë¶„ì„ í”Œë¡¯
    - íŠ¹ì§• ì¤‘ìš”ë„ ì‹œê°í™”
    - ì¸í„°ë™í‹°ë¸Œ ëŒ€ì‹œë³´ë“œ
    """
    
    def __init__(self, style: str = 'seaborn-v0_8', figsize: Tuple[int, int] = (12, 8)):
        """
        ì‹œê°í™” ë„êµ¬ ì´ˆê¸°í™”
        
        Args:
            style: matplotlib ìŠ¤íƒ€ì¼
            figsize: ê¸°ë³¸ ê·¸ë¦¼ í¬ê¸°
        """
        self.style = style
        self.figsize = figsize
        self.colors = ['#2E8B57', '#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FECA57']
        
        # matplotlib ì„¤ì •
        try:
            plt.style.use(style)
        except:
            plt.style.use('default')
            logger.warning(f"ìŠ¤íƒ€ì¼ '{style}'ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ ìŠ¤íƒ€ì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        self.logger = logging.getLogger(f"{__name__}.ResultVisualizer")
        
    def plot_performance_comparison(self, evaluations: Dict[str, Dict[str, Any]], 
                                  metrics: List[str] = None,
                                  save_path: Optional[str] = None) -> plt.Figure:
        """
        ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸
        
        Args:
            evaluations: ëª¨ë¸ë³„ í‰ê°€ ê²°ê³¼
            metrics: ë¹„êµí•  ë©”íŠ¸ë¦­ ë¦¬ìŠ¤íŠ¸
            save_path: ì €ì¥ ê²½ë¡œ
            
        Returns:
            matplotlib Figure ê°ì²´
        """
        if metrics is None:
            metrics = ['mae', 'mse', 'r2', 'mape']
        
        n_metrics = len(metrics)
        n_models = len(evaluations)
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('ğŸ‰ ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ', fontsize=16, fontweight='bold')
        
        axes = axes.flatten()
        
        for i, metric in enumerate(metrics[:4]):  # ìµœëŒ€ 4ê°œ ë©”íŠ¸ë¦­
            if i >= len(axes):
                break
                
            models = list(evaluations.keys())
            scores = [evaluations[model].get(metric, 0) for model in models]
            
            # ë°” ì°¨íŠ¸
            bars = axes[i].bar(models, scores, color=self.colors[:n_models], alpha=0.7)
            axes[i].set_title(f'{metric.upper()} ë¹„êµ', fontweight='bold')
            axes[i].set_ylabel(metric.upper())
            axes[i].tick_params(axis='x', rotation=45)
            
            # ê°’ í‘œì‹œ
            for bar, score in zip(bars, scores):
                height = bar.get_height()
                axes[i].text(bar.get_x() + bar.get_width()/2., height,
                           f'{score:.3f}', ha='center', va='bottom')
            
            # ìµœê³  ì„±ëŠ¥ ê°•ì¡°
            if metric in ['mae', 'mse', 'mape']:  # ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
                best_idx = np.argmin(scores)
            else:  # r2: ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ
                best_idx = np.argmax(scores)
            
            bars[best_idx].set_color('#FF6B6B')
            bars[best_idx].set_alpha(1.0)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            self.logger.info(f"ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸ ì €ì¥: {save_path}")
        
        return fig
    
    def plot_prediction_scatter(self, y_true: np.ndarray, y_pred: np.ndarray, 
                               model_name: str = "Model",
                               save_path: Optional[str] = None) -> plt.Figure:
        """
        ì˜ˆì¸¡ê°’ vs ì‹¤ì œê°’ ì‚°ì ë„
        
        Args:
            y_true: ì‹¤ì œ ê°’
            y_pred: ì˜ˆì¸¡ ê°’
            model_name: ëª¨ë¸ ì´ë¦„
            save_path: ì €ì¥ ê²½ë¡œ
            
        Returns:
            matplotlib Figure ê°ì²´
        """
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        fig.suptitle(f'ğŸ‰ {model_name} ì˜ˆì¸¡ ì •í™•ë„ ë¶„ì„', fontsize=14, fontweight='bold')
        
        # ì‚°ì ë„
        ax1.scatter(y_true, y_pred, alpha=0.6, color=self.colors[0], s=50)
        
        # ì™„ë²½í•œ ì˜ˆì¸¡ì„  (y=x)
        min_val = min(np.min(y_true), np.min(y_pred))
        max_val = max(np.max(y_true), np.max(y_pred))
        ax1.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, alpha=0.8, label='ì™„ë²½í•œ ì˜ˆì¸¡')
        
        # Â±1 Brix í—ˆìš© êµ¬ê°„
        ax1.fill_between([min_val, max_val], [min_val-1, max_val-1], [min_val+1, max_val+1], 
                        alpha=0.2, color='green', label='Â±1 Brix í—ˆìš©êµ¬ê°„')
        
        ax1.set_xlabel('ì‹¤ì œ ë‹¹ë„ (Brix)')
        ax1.set_ylabel('ì˜ˆì¸¡ ë‹¹ë„ (Brix)')
        ax1.set_title('ì˜ˆì¸¡ê°’ vs ì‹¤ì œê°’')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # ì˜¤ì°¨ íˆìŠ¤í† ê·¸ë¨
        errors = y_pred - y_true
        ax2.hist(errors, bins=20, alpha=0.7, color=self.colors[1], edgecolor='black')
        ax2.axvline(0, color='red', linestyle='--', linewidth=2, label='ì™„ë²½í•œ ì˜ˆì¸¡')
        ax2.axvline(np.mean(errors), color='orange', linestyle='-', linewidth=2, 
                   label=f'í‰ê·  ì˜¤ì°¨: {np.mean(errors):.3f}')
        
        ax2.set_xlabel('ì˜ˆì¸¡ ì˜¤ì°¨ (Brix)')
        ax2.set_ylabel('ë¹ˆë„')
        ax2.set_title('ì˜ˆì¸¡ ì˜¤ì°¨ ë¶„í¬')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            self.logger.info(f"ì˜ˆì¸¡ ì‚°ì ë„ ì €ì¥: {save_path}")
        
        return fig
    
    def plot_residual_analysis(self, y_true: np.ndarray, y_pred: np.ndarray,
                              model_name: str = "Model",
                              save_path: Optional[str] = None) -> plt.Figure:
        """
        ì”ì°¨ ë¶„ì„ í”Œë¡¯
        
        Args:
            y_true: ì‹¤ì œ ê°’
            y_pred: ì˜ˆì¸¡ ê°’
            model_name: ëª¨ë¸ ì´ë¦„
            save_path: ì €ì¥ ê²½ë¡œ
            
        Returns:
            matplotlib Figure ê°ì²´
        """
        residuals = y_true - y_pred
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle(f'ğŸ‰ {model_name} ì”ì°¨ ë¶„ì„', fontsize=14, fontweight='bold')
        
        # 1. ì”ì°¨ vs ì˜ˆì¸¡ê°’
        axes[0, 0].scatter(y_pred, residuals, alpha=0.6, color=self.colors[2])
        axes[0, 0].axhline(y=0, color='red', linestyle='--', linewidth=2)
        axes[0, 0].set_xlabel('ì˜ˆì¸¡ê°’')
        axes[0, 0].set_ylabel('ì”ì°¨')
        axes[0, 0].set_title('ì”ì°¨ vs ì˜ˆì¸¡ê°’')
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. ì”ì°¨ íˆìŠ¤í† ê·¸ë¨
        axes[0, 1].hist(residuals, bins=20, alpha=0.7, color=self.colors[3], edgecolor='black')
        axes[0, 1].axvline(0, color='red', linestyle='--', linewidth=2)
        axes[0, 1].set_xlabel('ì”ì°¨')
        axes[0, 1].set_ylabel('ë¹ˆë„')
        axes[0, 1].set_title('ì”ì°¨ ë¶„í¬')
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. Q-Q í”Œë¡¯ (ì •ê·œì„± ê²€ì •)
        from scipy import stats
        stats.probplot(residuals, dist="norm", plot=axes[1, 0])
        axes[1, 0].set_title('Q-Q í”Œë¡¯ (ì •ê·œì„± ê²€ì •)')
        axes[1, 0].grid(True, alpha=0.3)
        
        # 4. ì”ì°¨ vs ì‹¤ì œê°’
        axes[1, 1].scatter(y_true, residuals, alpha=0.6, color=self.colors[4])
        axes[1, 1].axhline(y=0, color='red', linestyle='--', linewidth=2)
        axes[1, 1].set_xlabel('ì‹¤ì œê°’')
        axes[1, 1].set_ylabel('ì”ì°¨')
        axes[1, 1].set_title('ì”ì°¨ vs ì‹¤ì œê°’')
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            self.logger.info(f"ì”ì°¨ ë¶„ì„ í”Œë¡¯ ì €ì¥: {save_path}")
        
        return fig
    
    def plot_feature_importance(self, importance_dict: Dict[str, Optional[List[Tuple[str, float]]]],
                               top_k: int = 15,
                               save_path: Optional[str] = None) -> plt.Figure:
        """
        íŠ¹ì§• ì¤‘ìš”ë„ ì‹œê°í™”
        
        Args:
            importance_dict: ëª¨ë¸ë³„ íŠ¹ì§• ì¤‘ìš”ë„ ë”•ì…”ë„ˆë¦¬
            top_k: ìƒìœ„ kê°œ íŠ¹ì§•ë§Œ í‘œì‹œ
            save_path: ì €ì¥ ê²½ë¡œ
            
        Returns:
            matplotlib Figure ê°ì²´
        """
        # Noneì´ ì•„ë‹Œ íŠ¹ì§• ì¤‘ìš”ë„ë§Œ í•„í„°ë§
        valid_models = {k: v for k, v in importance_dict.items() if v is not None}
        
        if not valid_models:
            self.logger.warning("í‘œì‹œí•  íŠ¹ì§• ì¤‘ìš”ë„ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return plt.figure()
        
        n_models = len(valid_models)
        
        if n_models == 1:
            fig, ax = plt.subplots(1, 1, figsize=(12, 8))
            axes = [ax]
        else:
            n_cols = min(n_models, 2)
            n_rows = (n_models + n_cols - 1) // n_cols
            fig, axes = plt.subplots(n_rows, n_cols, figsize=(6*n_cols, 6*n_rows))
            if n_models == 1:
                axes = [axes]
            else:
                axes = axes.flatten() if n_models > 1 else [axes]
        
        fig.suptitle('ğŸ‰ ëª¨ë¸ë³„ íŠ¹ì§• ì¤‘ìš”ë„ ë¶„ì„', fontsize=14, fontweight='bold')
        
        for i, (model_name, importance_list) in enumerate(valid_models.items()):
            if i >= len(axes):
                break
                
            # ìƒìœ„ kê°œ íŠ¹ì§• ì„ íƒ
            top_features = importance_list[:top_k]
            features, scores = zip(*top_features)
            
            # ìˆ˜í‰ ë°” ì°¨íŠ¸
            y_pos = np.arange(len(features))
            bars = axes[i].barh(y_pos, scores, color=self.colors[i % len(self.colors)], alpha=0.7)
            
            axes[i].set_yticks(y_pos)
            axes[i].set_yticklabels(features)
            axes[i].invert_yaxis()  # ìƒìœ„ íŠ¹ì§•ì´ ìœ„ì— ì˜¤ë„ë¡
            axes[i].set_xlabel('ì¤‘ìš”ë„')
            axes[i].set_title(f'{model_name} íŠ¹ì§• ì¤‘ìš”ë„')
            axes[i].grid(True, alpha=0.3)
            
            # ê°’ í‘œì‹œ
            for bar, score in zip(bars, scores):
                width = bar.get_width()
                axes[i].text(width, bar.get_y() + bar.get_height()/2., 
                           f'{score:.3f}', ha='left', va='center')
        
        # ë¹ˆ ì„œë¸Œí”Œë¡¯ ìˆ¨ê¸°ê¸°
        for i in range(len(valid_models), len(axes)):
            axes[i].set_visible(False)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            self.logger.info(f"íŠ¹ì§• ì¤‘ìš”ë„ í”Œë¡¯ ì €ì¥: {save_path}")
        
        return fig
    
    def plot_training_history(self, models_history: Dict[str, Dict[str, Any]],
                             save_path: Optional[str] = None) -> plt.Figure:
        """
        ëª¨ë¸ë³„ í›ˆë ¨ ê¸°ë¡ ì‹œê°í™”
        
        Args:
            models_history: ëª¨ë¸ë³„ í›ˆë ¨ ê¸°ë¡
            save_path: ì €ì¥ ê²½ë¡œ
            
        Returns:
            matplotlib Figure ê°ì²´
        """
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('ğŸ‰ ëª¨ë¸ í›ˆë ¨ ê¸°ë¡ ë¶„ì„', fontsize=14, fontweight='bold')
        
        models = list(models_history.keys())
        
        # 1. í›ˆë ¨ ì‹œê°„ ë¹„êµ
        training_times = [models_history[model].get('training_time', 0) for model in models]
        bars1 = axes[0, 0].bar(models, training_times, color=self.colors[:len(models)], alpha=0.7)
        axes[0, 0].set_title('ëª¨ë¸ë³„ í›ˆë ¨ ì‹œê°„')
        axes[0, 0].set_ylabel('ì‹œê°„ (ì´ˆ)')
        axes[0, 0].tick_params(axis='x', rotation=45)
        
        for bar, time_val in zip(bars1, training_times):
            height = bar.get_height()
            axes[0, 0].text(bar.get_x() + bar.get_width()/2., height,
                          f'{time_val:.1f}s', ha='center', va='bottom')
        
        # 2. í›ˆë ¨ vs ê²€ì¦ MAE
        train_maes = [models_history[model].get('train_mae', 0) for model in models]
        val_maes = [models_history[model].get('val_mae', 0) for model in models]
        
        x = np.arange(len(models))
        width = 0.35
        
        axes[0, 1].bar(x - width/2, train_maes, width, label='í›ˆë ¨ MAE', alpha=0.7, color=self.colors[0])
        axes[0, 1].bar(x + width/2, val_maes, width, label='ê²€ì¦ MAE', alpha=0.7, color=self.colors[1])
        axes[0, 1].set_title('í›ˆë ¨ vs ê²€ì¦ ì„±ëŠ¥ (MAE)')
        axes[0, 1].set_ylabel('MAE')
        axes[0, 1].set_xticks(x)
        axes[0, 1].set_xticklabels(models, rotation=45)
        axes[0, 1].legend()
        
        # 3. RÂ² ì ìˆ˜ ë¹„êµ
        train_r2s = [models_history[model].get('train_r2', 0) for model in models]
        val_r2s = [models_history[model].get('val_r2', 0) for model in models]
        
        axes[1, 0].bar(x - width/2, train_r2s, width, label='í›ˆë ¨ RÂ²', alpha=0.7, color=self.colors[2])
        axes[1, 0].bar(x + width/2, val_r2s, width, label='ê²€ì¦ RÂ²', alpha=0.7, color=self.colors[3])
        axes[1, 0].set_title('í›ˆë ¨ vs ê²€ì¦ ì„±ëŠ¥ (RÂ²)')
        axes[1, 0].set_ylabel('RÂ²')
        axes[1, 0].set_xticks(x)
        axes[1, 0].set_xticklabels(models, rotation=45)
        axes[1, 0].legend()
        
        # 4. ë°ì´í„°ì…‹ ì •ë³´
        n_samples = [models_history[model].get('n_samples', 0) for model in models]
        n_features = [models_history[model].get('n_features', 0) for model in models]
        
        ax_twin = axes[1, 1].twinx()
        bars2 = axes[1, 1].bar(x - width/2, n_samples, width, label='ìƒ˜í”Œ ìˆ˜', alpha=0.7, color=self.colors[4])
        bars3 = ax_twin.bar(x + width/2, n_features, width, label='íŠ¹ì§• ìˆ˜', alpha=0.7, color=self.colors[5])
        
        axes[1, 1].set_title('ë°ì´í„°ì…‹ ì •ë³´')
        axes[1, 1].set_ylabel('ìƒ˜í”Œ ìˆ˜')
        ax_twin.set_ylabel('íŠ¹ì§• ìˆ˜')
        axes[1, 1].set_xticks(x)
        axes[1, 1].set_xticklabels(models, rotation=45)
        
        # ë²”ë¡€ ê²°í•©
        lines1, labels1 = axes[1, 1].get_legend_handles_labels()
        lines2, labels2 = ax_twin.get_legend_handles_labels()
        axes[1, 1].legend(lines1 + lines2, labels1 + labels2, loc='upper left')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            self.logger.info(f"í›ˆë ¨ ê¸°ë¡ í”Œë¡¯ ì €ì¥: {save_path}")
        
        return fig
    
    def create_interactive_dashboard(self, evaluations: Dict[str, Dict[str, Any]],
                                   y_true_dict: Dict[str, np.ndarray],
                                   y_pred_dict: Dict[str, np.ndarray],
                                   save_path: Optional[str] = None) -> go.Figure:
        """
        ì¸í„°ë™í‹°ë¸Œ ëŒ€ì‹œë³´ë“œ ìƒì„± (Plotly)
        
        Args:
            evaluations: ëª¨ë¸ë³„ í‰ê°€ ê²°ê³¼
            y_true_dict: ëª¨ë¸ë³„ ì‹¤ì œê°’
            y_pred_dict: ëª¨ë¸ë³„ ì˜ˆì¸¡ê°’
            save_path: ì €ì¥ ê²½ë¡œ
            
        Returns:
            plotly Figure ê°ì²´
        """
        models = list(evaluations.keys())
        
        # ì„œë¸Œí”Œë¡¯ ìƒì„±
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=('ì„±ëŠ¥ ë¹„êµ', 'ì˜ˆì¸¡ ì •í™•ë„', 'ì˜¤ì°¨ ë¶„í¬', 'ëª¨ë¸ ìˆœìœ„'),
            specs=[[{"secondary_y": False}, {"secondary_y": False}],
                   [{"secondary_y": False}, {"secondary_y": False}]]
        )
        
        # 1. ì„±ëŠ¥ ë¹„êµ (MAE, RÂ²)
        mae_scores = [evaluations[model]['mae'] for model in models]
        r2_scores = [evaluations[model]['r2'] for model in models]
        
        fig.add_trace(
            go.Bar(name='MAE', x=models, y=mae_scores, marker_color='lightblue'),
            row=1, col=1
        )
        
        # 2. ì˜ˆì¸¡ ì •í™•ë„ (ì²« ë²ˆì§¸ ëª¨ë¸)
        if models:
            first_model = models[0]
            y_true = y_true_dict.get(first_model, np.array([]))
            y_pred = y_pred_dict.get(first_model, np.array([]))
            
            fig.add_trace(
                go.Scatter(
                    x=y_true, y=y_pred,
                    mode='markers',
                    name=f'{first_model} ì˜ˆì¸¡',
                    marker=dict(color='green', opacity=0.6)
                ),
                row=1, col=2
            )
            
            # ì™„ë²½í•œ ì˜ˆì¸¡ì„ 
            if len(y_true) > 0:
                min_val = min(np.min(y_true), np.min(y_pred))
                max_val = max(np.max(y_true), np.max(y_pred))
                fig.add_trace(
                    go.Scatter(
                        x=[min_val, max_val], y=[min_val, max_val],
                        mode='lines',
                        name='ì™„ë²½í•œ ì˜ˆì¸¡',
                        line=dict(color='red', dash='dash')
                    ),
                    row=1, col=2
                )
        
        # 3. ì˜¤ì°¨ ë¶„í¬
        if models:
            errors = y_pred_dict.get(first_model, np.array([])) - y_true_dict.get(first_model, np.array([]))
            if len(errors) > 0:
                fig.add_trace(
                    go.Histogram(x=errors, name='ì˜¤ì°¨ ë¶„í¬', marker_color='orange'),
                    row=2, col=1
                )
        
        # 4. ëª¨ë¸ ìˆœìœ„ (RÂ² ê¸°ì¤€)
        sorted_models = sorted(models, key=lambda x: evaluations[x]['r2'], reverse=True)
        sorted_r2 = [evaluations[model]['r2'] for model in sorted_models]
        
        fig.add_trace(
            go.Bar(
                name='RÂ² ìˆœìœ„', 
                x=sorted_models, 
                y=sorted_r2,
                marker_color='purple'
            ),
            row=2, col=2
        )
        
        # ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸
        fig.update_layout(
            title_text="ğŸ‰ ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸ ì¸í„°ë™í‹°ë¸Œ ëŒ€ì‹œë³´ë“œ",
            title_x=0.5,
            showlegend=True,
            height=700
        )
        
        # ì¶• ë¼ë²¨ ì—…ë°ì´íŠ¸
        fig.update_xaxes(title_text="ëª¨ë¸", row=1, col=1)
        fig.update_yaxes(title_text="MAE", row=1, col=1)
        fig.update_xaxes(title_text="ì‹¤ì œ ë‹¹ë„ (Brix)", row=1, col=2)
        fig.update_yaxes(title_text="ì˜ˆì¸¡ ë‹¹ë„ (Brix)", row=1, col=2)
        fig.update_xaxes(title_text="ì˜ˆì¸¡ ì˜¤ì°¨", row=2, col=1)
        fig.update_yaxes(title_text="ë¹ˆë„", row=2, col=1)
        fig.update_xaxes(title_text="ëª¨ë¸", row=2, col=2)
        fig.update_yaxes(title_text="RÂ²", row=2, col=2)
        
        if save_path:
            fig.write_html(save_path)
            self.logger.info(f"ì¸í„°ë™í‹°ë¸Œ ëŒ€ì‹œë³´ë“œ ì €ì¥: {save_path}")
        
        return fig
    
    def create_comprehensive_report(self, evaluations: Dict[str, Dict[str, Any]],
                                  y_true_dict: Dict[str, np.ndarray],
                                  y_pred_dict: Dict[str, np.ndarray],
                                  importance_dict: Dict[str, Optional[List[Tuple[str, float]]]],
                                  models_history: Dict[str, Dict[str, Any]],
                                  save_dir: Optional[str] = None) -> Dict[str, str]:
        """
        ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± (ëª¨ë“  ì‹œê°í™” í¬í•¨)
        
        Args:
            evaluations: ëª¨ë¸ë³„ í‰ê°€ ê²°ê³¼
            y_true_dict: ëª¨ë¸ë³„ ì‹¤ì œê°’
            y_pred_dict: ëª¨ë¸ë³„ ì˜ˆì¸¡ê°’
            importance_dict: ëª¨ë¸ë³„ íŠ¹ì§• ì¤‘ìš”ë„
            models_history: ëª¨ë¸ë³„ í›ˆë ¨ ê¸°ë¡
            save_dir: ì €ì¥ ë””ë ‰í† ë¦¬
            
        Returns:
            ìƒì„±ëœ íŒŒì¼ ê²½ë¡œ ë”•ì…”ë„ˆë¦¬
        """
        if save_dir:
            save_dir = Path(save_dir)
            save_dir.mkdir(parents=True, exist_ok=True)
        
        file_paths = {}
        
        try:
            # 1. ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸
            if save_dir:
                perf_path = save_dir / "performance_comparison.png"
                self.plot_performance_comparison(evaluations, save_path=str(perf_path))
                file_paths['performance_comparison'] = str(perf_path)
            
            # 2. ê° ëª¨ë¸ë³„ ì˜ˆì¸¡ ì‚°ì ë„
            for model_name in evaluations.keys():
                if model_name in y_true_dict and model_name in y_pred_dict:
                    if save_dir:
                        scatter_path = save_dir / f"prediction_scatter_{model_name}.png"
                        self.plot_prediction_scatter(
                            y_true_dict[model_name], 
                            y_pred_dict[model_name],
                            model_name,
                            save_path=str(scatter_path)
                        )
                        file_paths[f'scatter_{model_name}'] = str(scatter_path)
            
            # 3. ê° ëª¨ë¸ë³„ ì”ì°¨ ë¶„ì„
            for model_name in evaluations.keys():
                if model_name in y_true_dict and model_name in y_pred_dict:
                    if save_dir:
                        residual_path = save_dir / f"residual_analysis_{model_name}.png"
                        self.plot_residual_analysis(
                            y_true_dict[model_name],
                            y_pred_dict[model_name],
                            model_name,
                            save_path=str(residual_path)
                        )
                        file_paths[f'residual_{model_name}'] = str(residual_path)
            
            # 4. íŠ¹ì§• ì¤‘ìš”ë„
            if save_dir:
                importance_path = save_dir / "feature_importance.png"
                self.plot_feature_importance(importance_dict, save_path=str(importance_path))
                file_paths['feature_importance'] = str(importance_path)
            
            # 5. í›ˆë ¨ ê¸°ë¡
            if save_dir:
                history_path = save_dir / "training_history.png"
                self.plot_training_history(models_history, save_path=str(history_path))
                file_paths['training_history'] = str(history_path)
            
            # 6. ì¸í„°ë™í‹°ë¸Œ ëŒ€ì‹œë³´ë“œ
            if save_dir:
                dashboard_path = save_dir / "interactive_dashboard.html"
                self.create_interactive_dashboard(
                    evaluations, y_true_dict, y_pred_dict,
                    save_path=str(dashboard_path)
                )
                file_paths['interactive_dashboard'] = str(dashboard_path)
            
            self.logger.info(f"ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {len(file_paths)}ê°œ íŒŒì¼")
            
        except Exception as e:
            self.logger.error(f"ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        
        return file_paths


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_visualizer():
    """ì‹œê°í™” ëª¨ë“ˆ ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("ğŸ‰ ResultVisualizer í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    np.random.seed(42)
    
    # ê°€ì§œ í‰ê°€ ê²°ê³¼
    evaluations = {
        'GBT': {'mae': 0.8, 'mse': 1.2, 'r2': 0.85, 'mape': 0.08, 'performance_grade': 'GOOD'},
        'SVM': {'mae': 1.1, 'mse': 1.8, 'r2': 0.75, 'mape': 0.12, 'performance_grade': 'FAIR'},
        'RF': {'mae': 0.9, 'mse': 1.4, 'r2': 0.82, 'mape': 0.09, 'performance_grade': 'GOOD'}
    }
    
    # ê°€ì§œ ì˜ˆì¸¡ ë°ì´í„°
    y_true = np.random.randn(100) * 2 + 10
    y_pred_dict = {
        'GBT': y_true + np.random.randn(100) * 0.8,
        'SVM': y_true + np.random.randn(100) * 1.1,
        'RF': y_true + np.random.randn(100) * 0.9
    }
    y_true_dict = {model: y_true for model in evaluations.keys()}
    
    # ê°€ì§œ íŠ¹ì§• ì¤‘ìš”ë„
    feature_names = [f'íŠ¹ì§•_{i}' for i in range(10)]
    importance_dict = {
        'GBT': [(name, np.random.random()) for name in feature_names],
        'SVM': None,  # SVMì€ íŠ¹ì§• ì¤‘ìš”ë„ ì—†ìŒ
        'RF': [(name, np.random.random()) for name in feature_names]
    }
    
    # ê°€ì§œ í›ˆë ¨ ê¸°ë¡
    models_history = {
        'GBT': {'training_time': 25.3, 'train_mae': 0.7, 'val_mae': 0.8, 'train_r2': 0.9, 'val_r2': 0.85, 'n_samples': 100, 'n_features': 51},
        'SVM': {'training_time': 45.1, 'train_mae': 0.9, 'val_mae': 1.1, 'train_r2': 0.8, 'val_r2': 0.75, 'n_samples': 100, 'n_features': 51},
        'RF': {'training_time': 18.7, 'train_mae': 0.6, 'val_mae': 0.9, 'train_r2': 0.95, 'val_r2': 0.82, 'n_samples': 100, 'n_features': 51}
    }
    
    try:
        # ì‹œê°í™” ë„êµ¬ ìƒì„±
        visualizer = ResultVisualizer()
        print("âœ… ResultVisualizer ì´ˆê¸°í™” ì„±ê³µ")
        
        # ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸
        fig1 = visualizer.plot_performance_comparison(evaluations)
        print("âœ… ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸ ìƒì„± ì™„ë£Œ")
        plt.close(fig1)
        
        # ì˜ˆì¸¡ ì‚°ì ë„
        fig2 = visualizer.plot_prediction_scatter(y_true, y_pred_dict['GBT'], "GBT")
        print("âœ… ì˜ˆì¸¡ ì‚°ì ë„ ìƒì„± ì™„ë£Œ")
        plt.close(fig2)
        
        # ì”ì°¨ ë¶„ì„
        fig3 = visualizer.plot_residual_analysis(y_true, y_pred_dict['GBT'], "GBT")
        print("âœ… ì”ì°¨ ë¶„ì„ í”Œë¡¯ ìƒì„± ì™„ë£Œ")
        plt.close(fig3)
        
        # íŠ¹ì§• ì¤‘ìš”ë„
        fig4 = visualizer.plot_feature_importance(importance_dict)
        print("âœ… íŠ¹ì§• ì¤‘ìš”ë„ ì‹œê°í™” ì™„ë£Œ")
        plt.close(fig4)
        
        # í›ˆë ¨ ê¸°ë¡
        fig5 = visualizer.plot_training_history(models_history)
        print("âœ… í›ˆë ¨ ê¸°ë¡ ì‹œê°í™” ì™„ë£Œ")
        plt.close(fig5)
        
        # ì¸í„°ë™í‹°ë¸Œ ëŒ€ì‹œë³´ë“œ
        plotly_fig = visualizer.create_interactive_dashboard(evaluations, y_true_dict, y_pred_dict)
        print("âœ… ì¸í„°ë™í‹°ë¸Œ ëŒ€ì‹œë³´ë“œ ìƒì„± ì™„ë£Œ")
        
        print("\nğŸ‰ ResultVisualizer í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì‹œê°í™” ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        raise


if __name__ == "__main__":
    test_visualizer() 