"""
ğŸ‰ ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸ ë³€í™˜ê¸°
scikit-learn â†’ ONNX â†’ Core ML ë³€í™˜ íŒŒì´í”„ë¼ì¸

Author: Watermelon ML Team
Date: 2025-01-16 
Compatible with: scikit-learn 1.5.1
"""

import os
import json
import logging
import joblib
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path

# ë³€í™˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
import onnx
import skl2onnx
from skl2onnx import convert_sklearn
from skl2onnx.common.data_types import FloatTensorType
import coremltools

# sklearn ëª¨ë¸ë“¤
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler


class WatermelonModelConverter:
    """
    ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸ ë³€í™˜ í†µí•© í´ë˜ìŠ¤
    scikit-learn â†’ ONNX â†’ Core ML ì „ì²´ íŒŒì´í”„ë¼ì¸ ì§€ì›
    """
    
    def __init__(self, 
                 model_path: str = None,
                 scaler_path: str = None,
                 features_path: str = None,
                 output_dir: str = "models/mobile"):
        """
        ë³€í™˜ê¸° ì´ˆê¸°í™”
        
        Args:
            model_path: ì €ì¥ëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            scaler_path: ì €ì¥ëœ ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ ê²½ë¡œ  
            features_path: ì„ íƒëœ íŠ¹ì§• ì •ë³´ íŒŒì¼ ê²½ë¡œ
            output_dir: ë³€í™˜ëœ ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.model_path = model_path or "models/production/latest/watermelon_sweetness_model.pkl"
        self.scaler_path = scaler_path or "models/production/latest/feature_scaler.pkl"
        self.features_path = features_path or "models/production/latest/selected_features.json"
        self.output_dir = Path(output_dir)
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ë¡œê¹… ì„¤ì •
        self.logger = self._setup_logging()
        
        # ëª¨ë¸ ê´€ë ¨ ì†ì„±
        self.model = None
        self.scaler = None
        self.selected_features = None
        self.feature_names = None
        self.n_features = None
        
    def _setup_logging(self) -> logging.Logger:
        """ë¡œê¹… ì„¤ì •"""
        logger = logging.getLogger('WatermelonConverter')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            
        return logger
    
    def load_production_models(self) -> bool:
        """í”„ë¡œë•ì…˜ ëª¨ë¸ë“¤ì„ ë¡œë“œí•©ë‹ˆë‹¤"""
        try:
            self.logger.info("ğŸ”„ Loading production models...")
            
            # 1. ëª¨ë¸ ë¡œë“œ
            self.logger.info(f"   Loading model from: {self.model_path}")
            self.model = joblib.load(self.model_path)
            self.logger.info(f"   âœ… Model loaded: {type(self.model).__name__}")
            
            # 2. ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
            self.logger.info(f"   Loading scaler from: {self.scaler_path}")
            self.scaler = joblib.load(self.scaler_path)
            self.logger.info(f"   âœ… Scaler loaded: {type(self.scaler).__name__}")
            
            # 3. ì„ íƒëœ íŠ¹ì§• ì •ë³´ ë¡œë“œ
            self.logger.info(f"   Loading features from: {self.features_path}")
            with open(self.features_path, 'r') as f:
                features_info = json.load(f)
            
            # JSON íŒŒì¼ì˜ ì‹¤ì œ í‚¤ ì´ë¦„ ì‚¬ìš© ('features')
            self.selected_features = features_info['features']
            self.feature_names = self.selected_features
            self.n_features = len(self.selected_features)
            
            self.logger.info(f"   âœ… Features loaded: {self.n_features} features")
            self.logger.info(f"   Features: {self.feature_names}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to load models: {str(e)}")
            return False
    
    def convert_to_onnx(self, 
                       output_name: str = "watermelon_predictor.onnx") -> bool:
        """scikit-learn ëª¨ë¸ì„ ONNX í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        try:
            self.logger.info("ğŸ”„ Converting to ONNX format...")
            
            if self.model is None or self.scaler is None:
                raise ValueError("Models not loaded. Call load_production_models() first.")
            
            # ì»¤ìŠ¤í…€ Watermelon í´ë˜ìŠ¤ì—ì„œ ì‹¤ì œ sklearn ëª¨ë¸ ì¶”ì¶œ
            actual_model = self.model
            if hasattr(self.model, 'model') and self.model.model is not None:
                actual_model = self.model.model
                self.logger.info(f"   Extracted internal model: {type(actual_model).__name__}")
            else:
                self.logger.info(f"   Using model directly: {type(actual_model).__name__}")
            
            # ONNX ë³€í™˜ì„ ìœ„í•œ ì´ˆê¸° íƒ€ì… ì •ì˜
            initial_type = [('float_input', FloatTensorType([None, self.n_features]))]
            
            self.logger.info(f"   Input shape: [None, {self.n_features}]")
            self.logger.info(f"   Converting model type: {type(actual_model).__name__}")
            
            # ì‹¤ì œ sklearn ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜
            # íšŒê·€ ëª¨ë¸ì´ë¯€ë¡œ ë¶„ë¥˜ ê´€ë ¨ ì˜µì…˜ ì œê±°
            onnx_model = convert_sklearn(
                actual_model,  # ì¶”ì¶œëœ ì‹¤ì œ sklearn ëª¨ë¸ ì‚¬ìš©
                initial_types=initial_type,
                target_opset=12  # í˜¸í™˜ì„±ì„ ìœ„í•´ ì•ˆì •ì ì¸ opset ì‚¬ìš©
                # RandomForestRegressorëŠ” íšŒê·€ ëª¨ë¸ì´ë¯€ë¡œ ì˜µì…˜ ìƒëµ
            )
            
            # ONNX ëª¨ë¸ ì €ì¥
            output_path = self.output_dir / output_name
            onnx.save_model(onnx_model, str(output_path))
            
            # ONNX ëª¨ë¸ ê²€ì¦
            onnx.checker.check_model(onnx_model)
            
            self.logger.info(f"   âœ… ONNX model saved: {output_path}")
            self.logger.info(f"   Model size: {output_path.stat().st_size / 1024:.1f} KB")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ONNX conversion failed: {str(e)}")
            import traceback
            traceback.print_exc()
            return False
    
    def convert_onnx_to_coreml(self,
                              onnx_path: str = None,
                              output_name: str = "watermelon_predictor.mlmodel") -> bool:
        """ONNX ëª¨ë¸ì„ Core ML í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        try:
            self.logger.info("ğŸ”„ Converting ONNX to Core ML format...")
            
            # ONNX ëª¨ë¸ ê²½ë¡œ ì„¤ì •
            if onnx_path is None:
                onnx_path = self.output_dir / "watermelon_predictor.onnx"
            
            if not os.path.exists(onnx_path):
                raise FileNotFoundError(f"ONNX model not found: {onnx_path}")
            
            self.logger.info(f"   Loading ONNX model: {onnx_path}")
            
            # ONNX â†’ Core ML ë³€í™˜ (ìµœì‹  API ì‚¬ìš©)
            try:
                # ìµœì‹  coremltools API ì‹œë„
                coreml_model = coremltools.convert(
                    model=str(onnx_path),
                    source='onnx',
                    minimum_deployment_target=coremltools.target.iOS14,
                    compute_precision=coremltools.precision.FLOAT32
                )
            except Exception as e:
                self.logger.warning(f"Modern API failed: {e}")
                # ëŒ€ì•ˆ: êµ¬í˜• API ì‹œë„
                try:
                    import coremltools.converters
                    if hasattr(coremltools.converters, 'convert'):
                        coreml_model = coremltools.converters.convert(
                            model=str(onnx_path),
                            source='onnx'
                        )
                    else:
                        raise AttributeError("ONNX converter not available")
                except Exception as e2:
                    self.logger.error(f"Both APIs failed: {e2}")
                    raise e2
            
            # Core ML ëª¨ë¸ ë©”íƒ€ë°ì´í„° ì„¤ì •
            coreml_model.author = "Watermelon ML Team"
            coreml_model.license = "MIT"
            coreml_model.short_description = "ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸ (Traditional ML)"
            coreml_model.version = "1.0.0"
            
            # ì…ë ¥/ì¶œë ¥ ì„¤ëª… ì„¤ì •
            coreml_model.input_description['float_input'] = f"ìˆ˜ë°• ì˜¤ë””ì˜¤ íŠ¹ì§• ë²¡í„° ({self.n_features}ê°œ íŠ¹ì§•)"
            if hasattr(coreml_model, 'output_description'):
                output_keys = list(coreml_model.get_spec().description.output)
                if output_keys:
                    coreml_model.output_description[output_keys[0].name] = "ì˜ˆì¸¡ëœ ë‹¹ë„ (Brix)"
            
            # Core ML ëª¨ë¸ ì €ì¥
            output_path = self.output_dir / output_name
            coreml_model.save(str(output_path))
            
            self.logger.info(f"   âœ… Core ML model saved: {output_path}")
            self.logger.info(f"   Model size: {output_path.stat().st_size / 1024:.1f} KB")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Core ML conversion failed: {str(e)}")
            import traceback
            traceback.print_exc()
            return False
    
    def validate_conversion(self, 
                           num_test_samples: int = 10) -> Dict[str, Any]:
        """ë³€í™˜ëœ ëª¨ë¸ë“¤ì˜ ì •í™•ë„ë¥¼ ê²€ì¦"""
        try:
            self.logger.info("ğŸ”„ Validating converted models...")
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± (ëœë¤)
            np.random.seed(42)
            test_data = np.random.randn(num_test_samples, self.n_features).astype(np.float32)
            
            results = {
                'original': [],
                'onnx': [],
                'coreml': []
            }
            
            # 1. ì›ë³¸ ëª¨ë¸ ì˜ˆì¸¡
            scaled_data = self.scaler.transform(test_data)
            original_predictions = self.model.predict(scaled_data)
            results['original'] = original_predictions.tolist()
            
            # 2. ONNX ëª¨ë¸ ì˜ˆì¸¡ (ìˆëŠ” ê²½ìš°)
            onnx_path = self.output_dir / "watermelon_predictor.onnx"
            if onnx_path.exists():
                import onnxruntime as ort
                session = ort.InferenceSession(str(onnx_path))
                onnx_predictions = session.run(None, {'float_input': scaled_data})[0]
                results['onnx'] = onnx_predictions.flatten().tolist()
            
            # 3. Core ML ëª¨ë¸ ì˜ˆì¸¡ (ìˆëŠ” ê²½ìš°)
            coreml_path = self.output_dir / "watermelon_predictor.mlmodel"
            if coreml_path.exists():
                import coremltools
                coreml_model = coremltools.models.MLModel(str(coreml_path))
                coreml_predictions = []
                for i in range(num_test_samples):
                    input_dict = {'float_input': scaled_data[i:i+1]}
                    prediction = coreml_model.predict(input_dict)
                    # ì¶œë ¥ í‚¤ ì´ë¦„ì€ ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
                    pred_value = list(prediction.values())[0]
                    if isinstance(pred_value, np.ndarray):
                        pred_value = pred_value.item()
                    coreml_predictions.append(pred_value)
                results['coreml'] = coreml_predictions
            
            # 4. ì •í™•ë„ ë¹„êµ
            validation_results = {
                'test_samples': num_test_samples,
                'predictions': results,
                'accuracy': {}
            }
            
            # ì›ë³¸ vs ONNX ë¹„êµ
            if results['onnx']:
                diff = np.abs(np.array(results['original']) - np.array(results['onnx']))
                validation_results['accuracy']['onnx_mae'] = float(np.mean(diff))
                validation_results['accuracy']['onnx_max_diff'] = float(np.max(diff))
            
            # ì›ë³¸ vs Core ML ë¹„êµ
            if results['coreml']:
                diff = np.abs(np.array(results['original']) - np.array(results['coreml']))
                validation_results['accuracy']['coreml_mae'] = float(np.mean(diff))
                validation_results['accuracy']['coreml_max_diff'] = float(np.max(diff))
            
            self.logger.info("âœ… Validation completed")
            
            return validation_results
            
        except Exception as e:
            self.logger.error(f"âŒ Validation failed: {str(e)}")
            return {'error': str(e)}
    
    def convert_full_pipeline(self) -> Dict[str, bool]:
        """ì „ì²´ ë³€í™˜ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        self.logger.info("ğŸš€ Starting full conversion pipeline...")
        
        results = {
            'model_loaded': False,
            'onnx_converted': False,
            'coreml_converted': False
        }
        
        # 1. ëª¨ë¸ ë¡œë“œ
        if self.load_production_models():
            results['model_loaded'] = True
            
            # 2. ONNX ë³€í™˜
            if self.convert_to_onnx():
                results['onnx_converted'] = True
                
                # 3. Core ML ë³€í™˜
                if self.convert_onnx_to_coreml():
                    results['coreml_converted'] = True
        
        # ê²°ê³¼ ìš”ì•½
        self.logger.info("ğŸ“Š Conversion Pipeline Results:")
        self.logger.info(f"   Model Loading: {'âœ…' if results['model_loaded'] else 'âŒ'}")
        self.logger.info(f"   ONNX Conversion: {'âœ…' if results['onnx_converted'] else 'âŒ'}")
        self.logger.info(f"   Core ML Conversion: {'âœ…' if results['coreml_converted'] else 'âŒ'}")
        
        return results
    
    def save_conversion_report(self, validation_results: Dict[str, Any]) -> str:
        """ë³€í™˜ ê²°ê³¼ ë³´ê³ ì„œ ì €ì¥"""
        report_path = self.output_dir / "conversion_report.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# ğŸ‰ ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸ ë³€í™˜ ë³´ê³ ì„œ\n\n")
            f.write(f"**ìƒì„±ì¼**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**scikit-learn ë²„ì „**: 1.5.1\n")
            f.write(f"**íŠ¹ì§• ìˆ˜**: {self.n_features}\n\n")
            
            f.write("## ğŸ“‚ ë³€í™˜ëœ íŒŒì¼ë“¤\n\n")
            
            onnx_path = self.output_dir / "watermelon_predictor.onnx"
            coreml_path = self.output_dir / "watermelon_predictor.mlmodel"
            
            if onnx_path.exists():
                size_kb = onnx_path.stat().st_size / 1024
                f.write(f"- `watermelon_predictor.onnx` ({size_kb:.1f} KB)\n")
            
            if coreml_path.exists():
                size_kb = coreml_path.stat().st_size / 1024
                f.write(f"- `watermelon_predictor.mlmodel` ({size_kb:.1f} KB)\n")
            
            f.write("\n## ğŸ¯ ì •í™•ë„ ê²€ì¦ ê²°ê³¼\n\n")
            
            if 'accuracy' in validation_results:
                acc = validation_results['accuracy']
                if 'onnx_mae' in acc:
                    f.write(f"**ONNX ëª¨ë¸ ì •í™•ë„**:\n")
                    f.write(f"- í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (MAE): {acc['onnx_mae']:.6f}\n")
                    f.write(f"- ìµœëŒ€ ì˜¤ì°¨: {acc['onnx_max_diff']:.6f}\n\n")
                
                if 'coreml_mae' in acc:
                    f.write(f"**Core ML ëª¨ë¸ ì •í™•ë„**:\n")
                    f.write(f"- í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (MAE): {acc['coreml_mae']:.6f}\n")
                    f.write(f"- ìµœëŒ€ ì˜¤ì°¨: {acc['coreml_max_diff']:.6f}\n\n")
            
            f.write("## ğŸ‰ ì„ íƒëœ íŠ¹ì§•ë“¤\n\n")
            for i, feature in enumerate(self.feature_names, 1):
                f.write(f"{i}. `{feature}`\n")
            
            f.write("\n---\n")
            f.write("*Generated by WatermelonModelConverter*")
        
        return str(report_path)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ‰ Watermelon Model Converter")
    print("=" * 50)
    
    # ë³€í™˜ê¸° ì´ˆê¸°í™”
    converter = WatermelonModelConverter()
    
    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    results = converter.convert_full_pipeline()
    
    # ê²€ì¦ ì‹¤í–‰
    if results['onnx_converted'] or results['coreml_converted']:
        validation_results = converter.validate_conversion()
        report_path = converter.save_conversion_report(validation_results)
        print(f"\nğŸ“‹ Report saved: {report_path}")
    
    print("\nğŸ‰ Conversion completed!")


if __name__ == "__main__":
    main() 