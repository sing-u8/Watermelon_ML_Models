#!/usr/bin/env python3
"""
Mobile Model Conversion Script for iOS Deployment

This script converts the trained scikit-learn model to ONNX and Core ML formats
for mobile deployment, specifically targeting iOS applications.

Author: Watermelon ML Project Team
Date: 2025-01-15
"""

import sys
import os
import logging
import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path
import yaml
import joblib
import json
from typing import Optional, Tuple
import warnings
warnings.filterwarnings('ignore')

# Add project root to path
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.append(str(PROJECT_ROOT))

# Try to import conversion libraries
try:
    import skl2onnx
    from skl2onnx import convert_sklearn
    from skl2onnx.common.data_types import FloatTensorType
    print(f"âœ… skl2onnx version: {skl2onnx.__version__}")
    ONNX_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ ONNX conversion not available: {e}")
    ONNX_AVAILABLE = False

try:
    import onnx
    print(f"âœ… ONNX version: {onnx.__version__}")
    ONNX_IMPORT_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ ONNX import not available: {e}")
    ONNX_IMPORT_AVAILABLE = False

try:
    import coremltools as ct
    print(f"âœ… Core ML Tools version: {ct.__version__}")
    COREML_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Core ML conversion not available: {e}")
    COREML_AVAILABLE = False


def setup_logging(output_dir: Path) -> None:
    """Setup logging configuration."""
    log_file = output_dir / 'mobile_conversion.log'
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )


def load_production_model() -> tuple:
    """Load the latest production model and metadata."""
    logger = logging.getLogger(__name__)
    logger.info("=== í”„ë¡œë•ì…˜ ëª¨ë¸ ë¡œë“œ ===")
    
    # Find latest production model
    production_dir = PROJECT_ROOT / "models" / "production"
    latest_link = production_dir / "latest"
    
    if not latest_link.exists():
        raise FileNotFoundError("ìµœì‹  í”„ë¡œë•ì…˜ ëª¨ë¸ ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    model_dir = production_dir / latest_link.readlink()
    logger.info(f"ëª¨ë¸ ë””ë ‰í† ë¦¬: {model_dir}")
    
    # Load model and scaler
    model_file = model_dir / "watermelon_sweetness_model.pkl"
    scaler_file = model_dir / "feature_scaler.pkl"
    
    if not model_file.exists() or not scaler_file.exists():
        raise FileNotFoundError("ëª¨ë¸ ë˜ëŠ” ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    model = joblib.load(model_file)
    scaler = joblib.load(scaler_file)
    
    # Load metadata
    metadata_file = model_dir / "model_metadata.json"
    with open(metadata_file, 'r', encoding='utf-8') as f:
        metadata = json.load(f)
    
    # Load selected features
    features_file = model_dir / "selected_features.json"
    with open(features_file, 'r', encoding='utf-8') as f:
        features_info = json.load(f)
    
    selected_features = features_info['features']
    
    logger.info(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {len(selected_features)}ê°œ íŠ¹ì§•")
    logger.info(f"ëª¨ë¸ ì„±ëŠ¥: MAE {metadata['performance']['test_mae']:.4f}, RÂ² {metadata['performance']['test_r2']:.4f}")
    
    return model, scaler, selected_features, metadata, model_dir


def create_pipeline_model(model, scaler, selected_features: list):
    """Create a combined pipeline model for easier conversion."""
    from sklearn.pipeline import Pipeline
    from sklearn.compose import ColumnTransformer
    
    logger = logging.getLogger(__name__)
    logger.info("íŒŒì´í”„ë¼ì¸ ëª¨ë¸ ìƒì„± ì¤‘...")
    
    # Create a simple pipeline with scaler and model
    # Note: We'll handle feature selection separately since we're working with selected features
    pipeline = Pipeline([
        ('scaler', scaler),
        ('model', model.model)  # Access the underlying sklearn model
    ])
    
    logger.info("íŒŒì´í”„ë¼ì¸ ëª¨ë¸ ìƒì„± ì™„ë£Œ")
    return pipeline


def convert_to_onnx(pipeline, selected_features: list, output_dir: Path) -> Optional[Path]:
    """Convert scikit-learn model to ONNX format."""
    logger = logging.getLogger(__name__)
    
    if not ONNX_AVAILABLE:
        logger.warning("ONNX ë³€í™˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ì–´ ONNX ë³€í™˜ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None
    
    logger.info("=== ONNX ë³€í™˜ ì‹œì‘ ===")
    
    try:
        # Define input type (10 features, float32)
        n_features = len(selected_features)
        initial_type = [('input_features', FloatTensorType([None, n_features]))]
        
        # Convert to ONNX
        logger.info("scikit-learn â†’ ONNX ë³€í™˜ ì¤‘...")
        onnx_model = convert_sklearn(
            pipeline,
            initial_types=initial_type,
            target_opset=12  # Compatible with most deployment environments
        )
        
        # Save ONNX model
        onnx_file = output_dir / "watermelon_sweetness_model.onnx"
        with open(onnx_file, "wb") as f:
            f.write(onnx_model.SerializeToString())
        
        logger.info(f"ONNX ëª¨ë¸ ì €ì¥: {onnx_file}")
        
        # Verify ONNX model
        if ONNX_IMPORT_AVAILABLE:
            onnx_model_check = onnx.load(str(onnx_file))
            onnx.checker.check_model(onnx_model_check)
            logger.info("ONNX ëª¨ë¸ ê²€ì¦ ì™„ë£Œ")
        
        # Test ONNX model with sample data
        test_onnx_model(onnx_file, selected_features)
        
        return onnx_file
        
    except Exception as e:
        logger.error(f"ONNX ë³€í™˜ ì‹¤íŒ¨: {str(e)}")
        return None


def test_onnx_model(onnx_file: Path, selected_features: list) -> None:
    """Test ONNX model with sample data."""
    logger = logging.getLogger(__name__)
    
    try:
        import onnxruntime as ort
        
        # Load ONNX model
        sess = ort.InferenceSession(str(onnx_file))
        
        # Create sample input (10 features)
        sample_input = np.random.randn(1, len(selected_features)).astype(np.float32)
        
        # Run inference
        input_name = sess.get_inputs()[0].name
        result = sess.run(None, {input_name: sample_input})
        
        predicted_sweetness = result[0][0][0]  # Extract scalar value
        logger.info(f"ONNX ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ: ì˜ˆì¸¡ê°’ {predicted_sweetness:.2f} Brix")
        
    except ImportError:
        logger.warning("ONNX Runtimeì´ ì—†ì–´ ONNX ëª¨ë¸ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
    except Exception as e:
        logger.warning(f"ONNX ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")


def convert_to_coreml(onnx_file: Optional[Path], selected_features: list, 
                     metadata: dict, output_dir: Path) -> Optional[Path]:
    """Convert ONNX model to Core ML format for iOS deployment."""
    logger = logging.getLogger(__name__)
    
    if not COREML_AVAILABLE:
        logger.warning("Core ML Toolsê°€ ì—†ì–´ Core ML ë³€í™˜ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None
    
    if onnx_file is None or not onnx_file.exists():
        logger.warning("ONNX íŒŒì¼ì´ ì—†ì–´ Core ML ë³€í™˜ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None
    
    logger.info("=== Core ML ë³€í™˜ ì‹œì‘ ===")
    
    try:
        # Convert ONNX to Core ML
        logger.info("ONNX â†’ Core ML ë³€í™˜ ì¤‘...")
        
        # Load and convert
        coreml_model = ct.convert(
            str(onnx_file),
            minimum_deployment_target=ct.target.iOS14,  # iOS 14+ compatibility
            compute_precision=ct.precision.FLOAT32,
            convert_to="mlprogram"  # New Core ML format
        )
        
        # Set model metadata
        coreml_model.author = metadata['model_info']['author']
        coreml_model.short_description = "Watermelon Sweetness Prediction Model"
        coreml_model.version = metadata['model_info']['version']
        
        # Set input/output descriptions
        coreml_model.input_description['input_features'] = "Audio features extracted from watermelon sound (10 dimensions)"
        coreml_model.output_description['variable'] = "Predicted watermelon sweetness in Brix"
        
        # Create feature descriptions
        feature_descriptions = {}
        for i, feature in enumerate(selected_features):
            feature_descriptions[f"feature_{i}_{feature}"] = f"Audio feature: {feature}"
        
        # Save Core ML model
        coreml_file = output_dir / "WatermelonSweetness.mlpackage"
        coreml_model.save(str(coreml_file))
        
        logger.info(f"Core ML ëª¨ë¸ ì €ì¥: {coreml_file}")
        
        # Test Core ML model
        test_coreml_model(coreml_model, selected_features)
        
        return coreml_file
        
    except Exception as e:
        logger.error(f"Core ML ë³€í™˜ ì‹¤íŒ¨: {str(e)}")
        return None


def test_coreml_model(coreml_model, selected_features: list) -> None:
    """Test Core ML model with sample data."""
    logger = logging.getLogger(__name__)
    
    try:
        # Create sample input
        sample_input = {
            'input_features': np.random.randn(len(selected_features)).astype(np.float32)
        }
        
        # Run prediction
        result = coreml_model.predict(sample_input)
        predicted_sweetness = result['variable']
        
        logger.info(f"Core ML ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ: ì˜ˆì¸¡ê°’ {predicted_sweetness:.2f} Brix")
        
    except Exception as e:
        logger.warning(f"Core ML ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")


def create_mobile_metadata(original_metadata: dict, selected_features: list, 
                          onnx_file: Optional[Path], coreml_file: Optional[Path],
                          output_dir: Path) -> None:
    """Create metadata for mobile deployment."""
    logger = logging.getLogger(__name__)
    logger.info("ëª¨ë°”ì¼ ë°°í¬ ë©”íƒ€ë°ì´í„° ìƒì„± ì¤‘...")
    
    mobile_metadata = {
        'model_info': {
            'name': 'WatermelonSweetnessMobile',
            'version': original_metadata['model_info']['version'],
            'conversion_date': datetime.now().isoformat(),
            'original_model': 'RandomForest + Progressive Feature Selection',
            'mobile_formats': []
        },
        'performance': original_metadata['performance'],
        'features': {
            'count': len(selected_features),
            'names': selected_features,
            'input_shape': [len(selected_features)],
            'input_type': 'float32',
            'preprocessing_required': True
        },
        'deployment': {
            'target_platforms': ['iOS 14+'],
            'model_size_mb': 0,
            'inference_time_ms': '<100',
            'memory_requirements_mb': '<50'
        },
        'usage': {
            'input_description': 'Scaled audio features (10 dimensions) extracted from watermelon sound',
            'output_description': 'Predicted sweetness value in Brix (float)',
            'preprocessing_steps': [
                '1. Extract 51 audio features using AudioFeatureExtractor',
                '2. Select 10 specific features using feature list',
                '3. Apply StandardScaler normalization',
                '4. Input to model as float32 array'
            ]
        }
    }
    
    # Add format information
    if onnx_file and onnx_file.exists():
        mobile_metadata['model_info']['mobile_formats'].append('ONNX')
        mobile_metadata['files'] = mobile_metadata.get('files', {})
        mobile_metadata['files']['onnx'] = {
            'filename': onnx_file.name,
            'size_mb': round(onnx_file.stat().st_size / (1024 * 1024), 2),
            'format': 'ONNX v1.12+',
            'opset_version': 12
        }
    
    if coreml_file and coreml_file.exists():
        mobile_metadata['model_info']['mobile_formats'].append('Core ML')
        mobile_metadata['files'] = mobile_metadata.get('files', {})
        mobile_metadata['files']['coreml'] = {
            'filename': coreml_file.name,
            'format': 'Core ML (iOS 14+)',
            'deployment_target': 'iOS 14.0+'
        }
    
    # Save mobile metadata
    metadata_file = output_dir / 'mobile_model_metadata.json'
    with open(metadata_file, 'w', encoding='utf-8') as f:
        json.dump(mobile_metadata, f, indent=2, ensure_ascii=False)
    
    metadata_yaml = output_dir / 'mobile_model_metadata.yaml'
    with open(metadata_yaml, 'w', encoding='utf-8') as f:
        yaml.dump(mobile_metadata, f, default_flow_style=False, allow_unicode=True)
    
    logger.info(f"ëª¨ë°”ì¼ ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_file}")


def create_ios_integration_guide(selected_features: list, output_dir: Path) -> None:
    """Create iOS integration guide."""
    logger = logging.getLogger(__name__)
    logger.info("iOS í†µí•© ê°€ì´ë“œ ìƒì„± ì¤‘...")
    
    guide_content = f"""# ğŸ‰ iOS ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸ í†µí•© ê°€ì´ë“œ

## ğŸ“± ê°œìš”

ì´ ê°€ì´ë“œëŠ” Core ML ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸ì„ iOS ì•±ì— í†µí•©í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ“‹ ìš”êµ¬ì‚¬í•­

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­
- **iOS**: 14.0+
- **Xcode**: 12.0+
- **Swift**: 5.3+
- **Core ML**: 4.0+

### ëª¨ë¸ íŒŒì¼
- `WatermelonSweetness.mlpackage`: Core ML ëª¨ë¸
- `selected_features.json`: íŠ¹ì§• ì •ë³´

## ğŸš€ í†µí•© ë‹¨ê³„

### 1. í”„ë¡œì íŠ¸ì— ëª¨ë¸ ì¶”ê°€

```swift
// 1. WatermelonSweetness.mlpackageë¥¼ Xcode í”„ë¡œì íŠ¸ì— ë“œë˜ê·¸ ì•¤ ë“œë¡­
// 2. Target Membership í™•ì¸
// 3. ëª¨ë¸ í´ë˜ìŠ¤ ìë™ ìƒì„± í™•ì¸
```

### 2. Core ML í”„ë ˆì„ì›Œí¬ ì„í¬íŠ¸

```swift
import CoreML
import Foundation
```

### 3. ëª¨ë¸ ë¡œë“œ ë° ì´ˆê¸°í™”

```swift
class WatermelonPredictor {{
    private var model: WatermelonSweetness?
    
    init() {{
        do {{
            self.model = try WatermelonSweetness(configuration: MLModelConfiguration())
        }} catch {{
            print("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: \\(error)")
        }}
    }}
}}
```

### 4. íŠ¹ì§• ì¶”ì¶œ (ê°€ìƒ êµ¬í˜„)

```swift
// ì‹¤ì œë¡œëŠ” ì˜¤ë””ì˜¤ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”
func extractAudioFeatures(from audioData: Data) -> [Float]? {{
    // TODO: ì‹¤ì œ ì˜¤ë””ì˜¤ íŠ¹ì§• ì¶”ì¶œ êµ¬í˜„
    // í˜„ì¬ëŠ” í…ŒìŠ¤íŠ¸ìš© ëœë¤ ë°ì´í„°
    
    let selectedFeatures = [
{', '.join([f'        "{feature}"' for feature in selected_features])}
    ]
    
    // ëœë¤ í…ŒìŠ¤íŠ¸ ë°ì´í„° (ì‹¤ì œë¡œëŠ” ì˜¤ë””ì˜¤ì—ì„œ ì¶”ì¶œ)
    var features: [Float] = []
    for _ in 0..<{len(selected_features)} {{
        features.append(Float.random(in: -2.0...2.0))
    }}
    
    return features
}}
```

### 5. ë‹¹ë„ ì˜ˆì¸¡ í•¨ìˆ˜

```swift
func predictSweetness(audioData: Data) -> Float? {{
    guard let model = self.model else {{
        print("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        return nil
    }}
    
    // 1. ì˜¤ë””ì˜¤ì—ì„œ íŠ¹ì§• ì¶”ì¶œ
    guard let features = extractAudioFeatures(from: audioData) else {{
        print("íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨")
        return nil
    }}
    
    // 2. MLMultiArray ìƒì„±
    guard let mlArray = try? MLMultiArray(shape: [1, {len(selected_features)}], dataType: .float32) else {{
        print("MLMultiArray ìƒì„± ì‹¤íŒ¨")
        return nil
    }}
    
    // 3. íŠ¹ì§• ë°ì´í„° ë³µì‚¬
    for (index, value) in features.enumerated() {{
        mlArray[index] = NSNumber(value: value)
    }}
    
    // 4. ì˜ˆì¸¡ ìˆ˜í–‰
    do {{
        let input = WatermelonSweetnessInput(input_features: mlArray)
        let output = try model.prediction(input: input)
        
        // 5. ê²°ê³¼ ë°˜í™˜
        let sweetness = output.variable.floatValue
        return sweetness
    }} catch {{
        print("ì˜ˆì¸¡ ì‹¤íŒ¨: \\(error)")
        return nil
    }}
}}
```

### 6. UI ì—°ë™ ì˜ˆì œ

```swift
class ViewController: UIViewController {{
    @IBOutlet weak var recordButton: UIButton!
    @IBOutlet weak var resultLabel: UILabel!
    
    private let predictor = WatermelonPredictor()
    
    @IBAction func recordButtonTapped(_ sender: UIButton) {{
        // TODO: ì‹¤ì œ ì˜¤ë””ì˜¤ ë…¹ìŒ êµ¬í˜„
        let testAudioData = Data() // í…ŒìŠ¤íŠ¸ìš© ë¹ˆ ë°ì´í„°
        
        if let sweetness = predictor.predictSweetness(audioData: testAudioData) {{
            DispatchQueue.main.async {{
                self.resultLabel.text = String(format: "ë‹¹ë„: %.1f Brix", sweetness)
            }}
        }} else {{
            DispatchQueue.main.async {{
                self.resultLabel.text = "ì˜ˆì¸¡ ì‹¤íŒ¨"
            }}
        }}
    }}
}}
```

## ğŸ“Š ì„ íƒëœ íŠ¹ì§• ({len(selected_features)}ê°œ)

ëª¨ë¸ì€ ë‹¤ìŒ {len(selected_features)}ê°œ ìŒí–¥ íŠ¹ì§•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:

"""

    for i, feature in enumerate(selected_features, 1):
        guide_content += f"{i:2d}. `{feature}`\n"

    guide_content += f"""

## âš ï¸ ì£¼ì˜ì‚¬í•­

### ì„±ëŠ¥ ìµœì í™”

1. **ë©”ëª¨ë¦¬ ê´€ë¦¬**
   ```swift
   // ëª¨ë¸ì„ ì‹±ê¸€í†¤ìœ¼ë¡œ ê´€ë¦¬í•˜ì—¬ ë©”ëª¨ë¦¬ ì ˆì•½
   static let shared = WatermelonPredictor()
   ```

2. **ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬**
   ```swift
   DispatchQueue.global(qos: .userInitiated).async {{
       let result = self.predictSweetness(audioData: audioData)
       DispatchQueue.main.async {{
           // UI ì—…ë°ì´íŠ¸
       }}
   }}
   ```

3. **ì—ëŸ¬ ì²˜ë¦¬**
   ```swift
   enum PredictionError: Error {{
       case modelNotLoaded
       case featureExtractionFailed
       case predictionFailed
   }}
   ```

### ì˜¤ë””ì˜¤ ì²˜ë¦¬ ê³ ë ¤ì‚¬í•­

1. **ì‹¤ì œ êµ¬í˜„ í•„ìš”**
   - í˜„ì¬ ê°€ì´ë“œëŠ” íŠ¹ì§• ì¶”ì¶œì„ ê°€ìƒìœ¼ë¡œ êµ¬í˜„
   - ì‹¤ì œë¡œëŠ” ì˜¤ë””ì˜¤ ì‹ í˜¸ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”
   - Accelerate í”„ë ˆì„ì›Œí¬ ë˜ëŠ” ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©

2. **íŠ¹ì§• ì¶”ì¶œ ìˆœì„œ**
   - ì •í™•í•œ ìˆœì„œë¡œ {len(selected_features)}ê°œ íŠ¹ì§• ì¶”ì¶œ í•„ìˆ˜
   - StandardScalerì™€ ë™ì¼í•œ ì •ê·œí™” ì ìš© í•„ìš”

3. **í’ˆì§ˆ ê´€ë¦¬**
   - ë…¹ìŒ í’ˆì§ˆì´ ì˜ˆì¸¡ ì •í™•ë„ì— ì§ì ‘ ì˜í–¥
   - ë°°ê²½ ì†ŒìŒ ìµœì†Œí™” ê¶Œì¥

## ğŸ”§ ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œ

1. **ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨**
   - ëª¨ë¸ íŒŒì¼ì´ ì•± ë²ˆë“¤ì— í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸
   - Target Membership ì„¤ì • í™•ì¸

2. **ì˜ˆì¸¡ ì‹¤íŒ¨**
   - ì…ë ¥ ë°ì´í„° í˜•ì‹ í™•ì¸ (float32, shape: [1, {len(selected_features)}])
   - íŠ¹ì§• ì¶”ì¶œ ê²°ê³¼ ê²€ì¦

3. **ì„±ëŠ¥ ì €í•˜**
   - ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ ì˜ˆì¸¡ ìˆ˜í–‰ í”¼í•˜ê¸°
   - ëª¨ë¸ ì¬ì‚¬ìš©ìœ¼ë¡œ ì´ˆê¸°í™” ë¹„ìš© ì ˆì•½

### ë””ë²„ê¹… íŒ

```swift
// ì…ë ¥ ë°ì´í„° ê²€ì¦
func validateInput(_ features: [Float]) -> Bool {{
    guard features.count == {len(selected_features)} else {{
        print("íŠ¹ì§• ê°œìˆ˜ ë¶ˆì¼ì¹˜: ì˜ˆìƒ {len(selected_features)}, ì‹¤ì œ \\(features.count)")
        return false
    }}
    
    for (index, value) in features.enumerated() {{
        if value.isNaN || value.isInfinite {{
            print("ìœ íš¨í•˜ì§€ ì•Šì€ ê°’ at index \\(index): \\(value)")
            return false
        }}
    }}
    
    return true
}}
```

## ğŸ“ ì§€ì›

- **ëª¨ë¸ ë²„ì „**: v1.0.0
- **ì§€ì› iOS**: 14.0+
- **ì—…ë°ì´íŠ¸**: {datetime.now().strftime('%Y-%m-%d')}

---

*ì´ ê°€ì´ë“œëŠ” Core ML ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸ì˜ iOS í†µí•©ì— ëŒ€í•œ ì™„ì „í•œ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤.*
"""

    guide_file = output_dir / 'iOS_INTEGRATION_GUIDE.md'
    with open(guide_file, 'w', encoding='utf-8') as f:
        f.write(guide_content)
    
    logger.info(f"iOS í†µí•© ê°€ì´ë“œ ì €ì¥: {guide_file}")


def main():
    """Main conversion function."""
    # Create output directory
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_dir = PROJECT_ROOT / "models" / "mobile" / f"mobile_models_{timestamp}"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Setup logging
    setup_logging(output_dir)
    logger = logging.getLogger(__name__)
    
    logger.info("ğŸ¯ ëª¨ë°”ì¼ ëª¨ë¸ ë³€í™˜ ì‹œì‘")
    logger.info(f"ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    
    try:
        # Load production model
        model, scaler, selected_features, metadata, model_dir = load_production_model()
        
        # Create pipeline model
        pipeline = create_pipeline_model(model, scaler, selected_features)
        
        # Convert to ONNX
        onnx_file = convert_to_onnx(pipeline, selected_features, output_dir)
        
        # Convert to Core ML
        coreml_file = convert_to_coreml(onnx_file, selected_features, metadata, output_dir)
        
        # Create mobile metadata
        create_mobile_metadata(metadata, selected_features, onnx_file, coreml_file, output_dir)
        
        # Create iOS integration guide
        create_ios_integration_guide(selected_features, output_dir)
        
        # Copy selected features file
        import shutil
        shutil.copy2(model_dir / "selected_features.json", output_dir)
        
        # Print summary
        logger.info("\n" + "="*60)
        logger.info("ğŸ‰ ëª¨ë°”ì¼ ëª¨ë¸ ë³€í™˜ ì™„ë£Œ!")
        logger.info("="*60)
        
        conversion_summary = []
        if onnx_file:
            conversion_summary.append(f"âœ… ONNX: {onnx_file.name}")
        else:
            conversion_summary.append("âŒ ONNX: ë³€í™˜ ì‹¤íŒ¨")
            
        if coreml_file:
            conversion_summary.append(f"âœ… Core ML: {coreml_file.name}")
        else:
            conversion_summary.append("âŒ Core ML: ë³€í™˜ ì‹¤íŒ¨")
        
        for summary in conversion_summary:
            logger.info(summary)
        
        logger.info(f"íŠ¹ì§• ìˆ˜: {len(selected_features)}ê°œ")
        logger.info(f"iOS ë°°í¬ ì¤€ë¹„: {output_dir}")
        logger.info("="*60)
        
        # Create symlink to latest
        latest_dir = PROJECT_ROOT / "models" / "mobile" / "latest"
        if latest_dir.exists() or latest_dir.is_symlink():
            latest_dir.unlink()
        latest_dir.symlink_to(output_dir.name)
        logger.info(f"ìµœì‹  ëª¨ë°”ì¼ ëª¨ë¸ ë§í¬ ìƒì„±: {latest_dir}")
        
    except Exception as e:
        logger.error(f"ëª¨ë°”ì¼ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise
    finally:
        # Cleanup
        import gc
        gc.collect()


if __name__ == "__main__":
    main() 