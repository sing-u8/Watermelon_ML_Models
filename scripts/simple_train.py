#!/usr/bin/env python3
"""
ğŸ‰ ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸ ê°„ë‹¨ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸

í•µì‹¬ ê¸°ëŠ¥ë§Œ í¬í•¨í•œ ê°„ë‹¨í•œ ë²„ì „
"""

import os
import sys
from pathlib import Path
import yaml
import pandas as pd
import numpy as np
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python pathì— ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from src.models.traditional_ml import ModelFactory
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error

def main():
    """ê°„ë‹¨í•œ í›ˆë ¨ ì‹¤í–‰"""
    print("ğŸ‰ ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸ ê°„ë‹¨ í›ˆë ¨ ì‹œì‘")
    print("=" * 50)
    
    # 1. ë°ì´í„° ë¡œë“œ
    print("1. ë°ì´í„° ë¡œë“œ ì¤‘...")
    train_df = pd.read_csv(PROJECT_ROOT / 'data' / 'splits' / 'full_dataset' / 'train.csv')
    val_df = pd.read_csv(PROJECT_ROOT / 'data' / 'splits' / 'full_dataset' / 'val.csv')
    test_df = pd.read_csv(PROJECT_ROOT / 'data' / 'splits' / 'full_dataset' / 'test.csv')
    
    # íŠ¹ì§•ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
    feature_cols = [col for col in train_df.columns if col != 'sweetness']
    X_train = train_df[feature_cols].values
    y_train = train_df['sweetness'].values
    X_val = val_df[feature_cols].values
    y_val = val_df['sweetness'].values
    X_test = test_df[feature_cols].values
    y_test = test_df['sweetness'].values
    
    print(f"   - í›ˆë ¨: {len(X_train)}ê°œ")
    print(f"   - ê²€ì¦: {len(X_val)}ê°œ")
    print(f"   - í…ŒìŠ¤íŠ¸: {len(X_test)}ê°œ")
    print(f"   - íŠ¹ì§• ìˆ˜: {len(feature_cols)}ê°œ")
    
    # 2. íŠ¹ì§• ìŠ¤ì¼€ì¼ë§
    print("2. íŠ¹ì§• ìŠ¤ì¼€ì¼ë§ ì¤‘...")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)
    X_test_scaled = scaler.transform(X_test)
    
    # 3. ëª¨ë¸ ìƒì„± ë° í›ˆë ¨
    models = {}
    results = {}
    
    # 3.1 Gradient Boosting
    print("3. ëª¨ë¸ í›ˆë ¨ ì¤‘...")
    print("   3.1 Gradient Boosting...")
    gbt_model = ModelFactory.create_model('gradient_boosting')
    gbt_model.fit(X_train_scaled, y_train)
    models['GBT'] = gbt_model
    
    # 3.2 Random Forest
    print("   3.2 Random Forest...")
    rf_model = ModelFactory.create_model('random_forest')
    rf_model.fit(X_train_scaled, y_train)
    models['RF'] = rf_model
    
    # 3.3 SVM
    print("   3.3 SVM...")
    svm_model = ModelFactory.create_model('svm')
    svm_model.fit(X_train_scaled, y_train)
    models['SVM'] = svm_model
    
    # 4. í‰ê°€
    print("4. ëª¨ë¸ í‰ê°€ ì¤‘...")
    print(f"{'ëª¨ë¸':<6} {'ë°ì´í„°ì…‹':<6} {'MAE':<8} {'RÂ²':<8} {'RMSE':<8}")
    print("-" * 50)
    
    best_model_name = None
    best_mae = float('inf')
    
    for model_name, model in models.items():
        for dataset_name, X_data, y_data in [
            ('í›ˆë ¨', X_train_scaled, y_train),
            ('ê²€ì¦', X_val_scaled, y_val),
            ('í…ŒìŠ¤íŠ¸', X_test_scaled, y_test)
        ]:
            y_pred = model.predict(X_data)
            mae = mean_absolute_error(y_data, y_pred)
            r2 = r2_score(y_data, y_pred)
            rmse = np.sqrt(mean_squared_error(y_data, y_pred))
            
            print(f"{model_name:<6} {dataset_name:<6} {mae:<8.3f} {r2:<8.3f} {rmse:<8.3f}")
            
            # í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ìœ¼ë¡œ ìµœê³  ëª¨ë¸ ì„ ì •
            if dataset_name == 'í…ŒìŠ¤íŠ¸' and mae < best_mae:
                best_mae = mae
                best_model_name = model_name
    
    print("-" * 50)
    print(f"ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name} (í…ŒìŠ¤íŠ¸ MAE: {best_mae:.3f})")
    
    # 5. ëª©í‘œ ë‹¬ì„± í™•ì¸
    print("\n5. ì„±ëŠ¥ ëª©í‘œ ë‹¬ì„± í™•ì¸:")
    target_mae = 1.0
    target_r2 = 0.8
    
    test_results = {}
    for model_name, model in models.items():
        y_pred = model.predict(X_test_scaled)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        test_results[model_name] = {'mae': mae, 'r2': r2}
    
    models_meeting_mae = sum(1 for result in test_results.values() if result['mae'] < target_mae)
    models_meeting_r2 = sum(1 for result in test_results.values() if result['r2'] > target_r2)
    
    print(f"   - MAE < {target_mae}: {models_meeting_mae}/3 ëª¨ë¸ ë‹¬ì„±")
    print(f"   - RÂ² > {target_r2}: {models_meeting_r2}/3 ëª¨ë¸ ë‹¬ì„±")
    
    if best_mae < target_mae:
        print(f"   âœ… ì£¼ìš” ëª©í‘œ ë‹¬ì„±! (MAE < {target_mae})")
    else:
        print(f"   âŒ ì£¼ìš” ëª©í‘œ ë¯¸ë‹¬ì„± (MAE >= {target_mae})")
    
    # 6. ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
    print("\n6. ëª¨ë¸ ì €ì¥ ì¤‘...")
    os.makedirs(PROJECT_ROOT / 'models' / 'saved', exist_ok=True)
    
    best_model = models[best_model_name]
    model_path = PROJECT_ROOT / 'models' / 'saved' / 'best_model_simple.pkl'
    best_model.save_model(str(model_path))
    
    # ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
    import joblib
    scaler_path = PROJECT_ROOT / 'models' / 'saved' / 'scaler_simple.pkl'
    joblib.dump(scaler, scaler_path)
    
    # ê²°ê³¼ ìš”ì•½ ì €ì¥
    summary = {
        'timestamp': datetime.now().isoformat(),
        'best_model': best_model_name,
        'test_performance': test_results,
        'target_achieved': best_mae < target_mae,
        'feature_count': len(feature_cols)
    }
    
    summary_path = PROJECT_ROOT / 'models' / 'saved' / 'training_summary_simple.yaml'
    with open(summary_path, 'w', encoding='utf-8') as f:
        yaml.dump(summary, f, default_flow_style=False, allow_unicode=True)
    
    print(f"   - ëª¨ë¸: {model_path}")
    print(f"   - ìŠ¤ì¼€ì¼ëŸ¬: {scaler_path}")
    print(f"   - ìš”ì•½: {summary_path}")
    
    print("\nğŸ‰ ê°„ë‹¨ í›ˆë ¨ ì™„ë£Œ!")
    
    return 0

if __name__ == "__main__":
    sys.exit(main()) 